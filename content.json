{"meta":{"title":"Caesar Bao's blogs","subtitle":null,"description":"Someone becomes silent for getting more people hear his voice.","author":"Caesar Bao","url":"http://yoursite.com"},"pages":[{"title":"categories","date":"2019-01-20T10:22:15.000Z","updated":"2019-01-20T10:23:02.910Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"search","date":"2019-01-20T10:23:56.000Z","updated":"2019-01-20T10:24:19.893Z","comments":true,"path":"search/index.html","permalink":"http://yoursite.com/search/index.html","excerpt":"","text":""}],"posts":[{"title":"五种基本滤波器","slug":"OpenCV-Learning-Day-2","date":"2019-03-12T13:48:45.000Z","updated":"2019-03-12T14:10:27.619Z","comments":true,"path":"2019/03/12/OpenCV-Learning-Day-2/","link":"","permalink":"http://yoursite.com/2019/03/12/OpenCV-Learning-Day-2/","excerpt":"前言：本片主要介绍五个常见的滤波器（线性滤波、方框滤波、高斯滤波、中值滤波、双边滤波），文章基本是我翻阅博客整理而成的笔记～目前水平太菜了自己写不了基础知识，只能整理大神们的文章了！","text":"前言：本片主要介绍五个常见的滤波器（线性滤波、方框滤波、高斯滤波、中值滤波、双边滤波），文章基本是我翻阅博客整理而成的笔记～目前水平太菜了自己写不了基础知识，只能整理大神们的文章了！ 测试代码：1234567891011121314151617181920212223242526272829#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123;Mat srcImage = imread(\"Bilbo.jpg\");imshow(\"Input Image\",srcImage);Mat dstImage;blur(srcImage,dstImage,Size(3,3));imshow(\"blur\",dstImage);boxFilter(srcImage,dstImage,-1,Size(3,3));imshow(\"boxFilter\",dstImage);GaussianBlur(srcImage,dstImage,Size(3,3),0,0);imshow(\"GaussianBlur\",dstImage);medianBlur(srcImage,dstImage,3);imshow(\"medianBlur\",dstImage);bilateralFilter(srcImage,dstImage,100,0,0);imshow(\"bilateralFilter\",dstImage);waitKey(0);&#125; 效果图： 一、基本滤波器1.线性滤波均值滤波blur：将一个区域内的像素值求和取平均值，然后用这个平均值替换区域中心的像素值。计算速度很快，但是在去躁的同时会模糊很多细节部分，不容易保存细节。 函数原型：12345void blur( InputArray src, //输入图像OutputArray dst, //输出图像Size ksize, //内核大小Point anchor = Point(-1,-1), //锚点位置，默认为中心点int borderType = BORDER_DEFAULT ); //用于推断图像外部像素的某种边界模式，默认值BORDER_DEFAULT 效果图： 方框滤波boxFilter：算法和均值滤波相似，优缺点也相同，均值滤波算是方框滤波的特殊版本。 效果图： 高斯滤波GaussianBlur：高斯滤波是专门用于消除满足高斯分布(正态分布)的误差而存在的滤波，此时邻域算子是专门的高斯核，图像中的像素与高斯核做卷积，生成的结果加权平均存放到目标像素中，权重按照二维正态分布，对于抑制符合正态分布的噪声非常有效，并可以增强图像值不同比例下的图像效果。 函数原型：12345678void GaussianBlur(InputArray src, OutputArray dst, Size ksize, //表示高斯核函数在Y方向的的标准偏差，若sigmaY为零，就将它设为sigmaX，如果sigmaX和sigmaY都是0，那么就由ksize.width和ksize.height计算出来double sigmaX, double sigmaY=0, int borderType=BORDER_DEFAULT); 效果图： 2.非线性滤波中值滤波medianBlur：基本思想就是用像素点的领域灰度的中值来代替该像素点的灰度值，该方法在去除脉冲噪声、椒盐噪声的同时又能保留图像的细节（不会出现边缘模糊的情况）。中值滤波跟均值滤波的思想看起来很相似，只是一个取平均值，一个取中位数，但是均值滤波的计算速度是中值滤波的五倍，具体原因可以看总结。 函数原型：1234void medianBlur(InputArray src,OutputArray dst, int ksize) //孔径的线性尺寸（aperture linear size），必须为奇数 效果图： 双边滤波bilateralFilter：双边滤波的最大特点就是做边缘保存，保边去噪。大概的原理是给定一个范围，如果某些区域点与点之间如果数值差距超出范围，那么这个区域就不滤波了，能够很好的保留图像轮廓。函数原型：1234567void bilateralFilter(InputArray src, OutputArray dst, int d, //在过滤过程中每个像素邻域的直径范围double sigmaColor, //颜色空间过滤器的sigma值double sigmaSpace, //坐标空间中滤波器的sigma值int borderType=BORDER_DEFAULT ) //用于推断图像外部像素的某种边界模式，默认值BORDER_DEFAULT 注：对sigmaColor、和sigmaSpace两个参数存在比较大的疑惑，因为我不管怎么调后面的参数，效果图好像和原图没有差别…效果图： 3.线性滤波和非线性滤波的区别线性滤波器的原始数据与滤波结果是一种算术运算，即用加减乘除等运算实现，如均值滤波器（模板内像素灰度值的平均值）、高斯滤波器（高斯加权平均值）等。由于线性滤波器是算术运算，有固定的模板，因此滤波器的转移函数是可以确定并且是唯一的（转移函数即模板的傅里叶变换）。 非线性滤波器的原始数据与滤波结果是一种逻辑关系，即用逻辑运算实现，如最大值滤波器、最小值滤波器、中值滤波器等，是通过比较一定邻域内的灰度值大小来实现的，没有固定的模板，因而也就没有特定的转移函数（因为没有模板作傅里叶变换），另外，膨胀和腐蚀也是通过最大值、最小值滤波器实现的。（这就是为什么均值滤波要比中值滤波快五倍的原因：需要通过排序确定中值后才能生成模版） 参考资料：什么是线性滤波、非线性滤波https://www.cnblogs.com/snowxshy/p/3855011.htmlopencv中的各种滤波https://www.jianshu.com/p/8f4024742821OpenCv基本滤波算法小结 blockquotehttps://blog.csdn.net/fzhykx/article/details/79546549opencv中的各种滤波函数https://blog.csdn.net/zoucharming/article/details/70197863OpenCV探索之路（三）：滤波操作https://www.cnblogs.com/skyfsm/p/6873188.html","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"了解卷积：深度学习中的卷积之我见","slug":"Something-Fundamental-about-Convolution","date":"2019-03-11T12:07:09.000Z","updated":"2019-03-11T12:40:04.727Z","comments":true,"path":"2019/03/11/Something-Fundamental-about-Convolution/","link":"","permalink":"http://yoursite.com/2019/03/11/Something-Fundamental-about-Convolution/","excerpt":"一、前言最近在学习OpenCV的过程中接触到了几个常见的算子（canny算子、sobel算子、laplace算子），并对其中的卷积产生了非常大的困惑，此为其一；同时，卷积也可以说是深度学习当中最重要的概念，如CNN神经网络（Conventional Neural Net）更是深度学习中最为常见，也是最为优秀的神经网络之一，此为其二。可以说，卷积是一道不得不迈的门槛，迈过去能办事，迈不过去就只能吹牛了。在翻阅许多博客之后，我发现每个人对卷积的理解都不尽相同，每一篇都能让我有或多或少的收获，但没有一篇能让我完全理解，因此我想站在自己的角度上，稍微谈谈我对卷积以及卷积在深度学习中的使用的一些浅见。","text":"一、前言最近在学习OpenCV的过程中接触到了几个常见的算子（canny算子、sobel算子、laplace算子），并对其中的卷积产生了非常大的困惑，此为其一；同时，卷积也可以说是深度学习当中最重要的概念，如CNN神经网络（Conventional Neural Net）更是深度学习中最为常见，也是最为优秀的神经网络之一，此为其二。可以说，卷积是一道不得不迈的门槛，迈过去能办事，迈不过去就只能吹牛了。在翻阅许多博客之后，我发现每个人对卷积的理解都不尽相同，每一篇都能让我有或多或少的收获，但没有一篇能让我完全理解，因此我想站在自己的角度上，稍微谈谈我对卷积以及卷积在深度学习中的使用的一些浅见。 二、一维卷积及其意义在数学中，卷积地表示是一维的。我们称 (f*g)(n) 为 f,g 的卷积，其连续的定义为：(f∗g)(n)=∫∞−∞f(τ)g(n−τ)dτ其离散的定义为：(f∗g)(n)=∑−∞∞f(τ)g(n−τ) 好家伙，看是看得懂，可卷积出来的结果究竟是个什么东西？它的意义是什么？我看到的最能让我明白的是这两个答案：如何通俗易懂地解释卷积？ - 张俊博的回答 - 知乎https://www.zhihu.com/question/22298352/answer/34267457卷积为什么叫「卷」积？ - 荆哲的回答 - 知乎https://www.zhihu.com/question/54677157/answer/141245297 看完你理解一下就会知道，卷积的一个重要意义就是：一个函数在另一个函数上的加权叠加。在深度学习中，我们把一个函数看作是输入的图像代表的矩阵（Input Image），把另一个图像看作是卷积核（Convolution Kernel），两者卷积，就是输入图像和卷积核的加权叠加，权重越大，卷积值越大，就代表越重要。这是一个陌生的概念，我先按下不提。我之所以会提及一维卷积，是因为一维的卷积更能帮助我们理解卷积的意义：加权叠加。这就是为什么要用卷积的原因所在。 三、人类视觉原理在谈及卷积在深度学习的应用之前，我想先分享一下深度学习神经网络是怎么出现的，这是摘自Alex Cai的博客http://www.cnblogs.com/alexcai/p/5506806.html它更能帮助我们了解神经网络的作用，以及卷积在其中扮演的角色。 深度学习的许多研究成果，离不开对大脑认知原理的研究，尤其是视觉原理的研究。 1981 年的诺贝尔医学奖，颁发给了 David Hubel（出生于加拿大的美国神经生物学家） 和TorstenWiesel，以及 Roger Sperry。前两位的主要贡献，是“发现了视觉系统的信息处理”，可视皮层是分级的。 人类的视觉原理如下：从原始信号摄入开始（瞳孔摄入像素 Pixels），接着做初步处理（大脑皮层某些细胞发现边缘和方向），然后抽象（大脑判定，眼前的物体的形状，是圆形的），然后进一步抽象（大脑进一步判定该物体是只气球）。下面是人脑进行人脸识别的一个示例： 对于不同的物体，人类视觉也是通过这样逐层分级，来进行认知的： 我们可以看到，在最底层特征基本上是类似的，就是各种边缘，越往上，越能提取出此类物体的一些特征（轮子、眼睛、躯干等），到最上层，不同的高级特征最终组合成相应的图像，从而能够让人类准确的区分不同的物体。 那么我们可以很自然的想到：可以不可以模仿人类大脑的这个特点，构造多层的神经网络，较低层的识别初级的图像特征，若干底层特征组成更上一层特征，最终通过多个层级的组合，最终在顶层做出分类呢？答案是肯定的，这也是许多深度学习算法（包括CNN）的灵感来源。 四、深度学习中的卷积由上一节可见，机器学习脱胎于人类视觉原理，而卷积的作用，就是把关键细节抽象化，因为同一类事物总是有各种相同或者相似的细节，记得卷积的作用吗？加权叠加可以提取出相同的、我们所需要的细节并强调它，一层层的提取和强调，就可以生成机器识物的“逻辑”。 在深度学习中，我们所使用的卷积是二维的，因为机器所“看”的图片实质上是一个矩阵，那么相应的，卷积核也是一个矩阵，这个卷积核在 2 维输入数据上“滑动”，对当前输入的部分元素进行矩阵乘法，然后将结果汇为单个输出像素。 这里曾是让我最百思不得其解的地方，可能是智商限制了我的发挥，很长时间有一个问题困扰着我：一维卷积和二维卷积有什么关系？为什么二维卷积会这么计算而不是别的什么方法？其实稍微转换一下角度就很好理解：把输入图像的矩阵和卷积核排成一行而不是将它以二维的形式放置，就会发现它们其实就是f(x)和g(x)以离散的形式所构成的函数！实质上图像正是以这样一种方式，通过训练得出的卷积核，来抽象出图像的特征：强调个性，抑制共性，抽丝剥茧出一套“逻辑”来。 五、后记以上是我在一天的学习后所做的总结，本文没有涉及任何高级的操作，只是我对卷积的一些浅显认识过程。我认为，在深度学习中，打好基础，掌握必要概念非常重要，它会对后面的学习起到意想不到的效果！希望能给予想要学习深度学习的读者一个比较清楚的认识！ 参考链接：如何通俗易懂地解释卷积？ - 张俊博的回答 - 知乎https://www.zhihu.com/question/22298352/answer/34267457卷积为什么叫「卷」积？ - 荆哲的回答 - 知乎https://www.zhihu.com/question/54677157/answer/141245297Alex Cai的博客http://www.cnblogs.com/alexcai/p/5506806.html以及所有我看过的博客们！转载请注明出处","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/categories/Deep-Learning/"}],"tags":[]},{"title":"OpenCV Learning Day 1","slug":"OpenCV-Learning-Day-1","date":"2019-03-10T07:43:23.000Z","updated":"2019-03-10T08:05:18.852Z","comments":true,"path":"2019/03/10/OpenCV-Learning-Day-1/","link":"","permalink":"http://yoursite.com/2019/03/10/OpenCV-Learning-Day-1/","excerpt":"本文内容包括：一、erode 图像腐蚀（dilate 图像膨胀）二、blur 均值滤波三、canny边缘检测 文末提供测试图片","text":"本文内容包括：一、erode 图像腐蚀（dilate 图像膨胀）二、blur 均值滤波三、canny边缘检测 文末提供测试图片 一、erode 图像腐蚀（dilate 图像膨胀）1234567891011121314151617#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123;Mat srcImage = imread(\"Phone.png\");imshow(\"former\",srcImage);Mat element = getStructuringElement(MORPH_RECT,Size(15,15));Mat dstImage;erode(srcImage,dstImage,element);imshow(\"later\",dstImage);waitKey(0);return 0;&#125; 1.imread函数只能读取绝对路径，不能读取相对路径，存在疑问。已解决：cmake编译时出现问题，需在CMakeLists.txt中加入一行1aux_source_directory(. DIR_SRCS)对整个文件夹进行扫描即可读取到图片的相对路径。（Xcode肯定没这问题但是我不想用哈哈～谁叫它长得没有VS Code好看） 2.getStructuringElement函数原型：1Mat getStructuringElement(int shape, Size esize, Point anchor = Point(-1, -1));函数的第一个参数表示内核的形状，有三种形状可以选择。矩形：MORPH_RECT;交叉形：MORPH_CORSS;椭圆形：MORPH_ELLIPSE;第二和第三个参数分别是内核的尺寸以及锚点的位置。一般在调用erode以及dilate函数之前，先定义一个Mat类型的变量来获得getStructuringElement函数的返回值。对于锚点的位置，有默认值Point（-1,-1），表示锚点位于中心点。element形状唯一依赖锚点位置，其他情况下，锚点只是影响了形态学运算结果的偏移。 3.erode 图像腐蚀（dilate 图像膨胀）erode 函数原型：12void erode( const Mat&amp; src, Mat&amp; dst, const Mat&amp; element,Point anchor=Point(-1,-1), int iterations=1,int borderType=BORDER_CONSTANT,const Scalar&amp; borderValue=morphologyDefaultBorderValue() );dilate 函数原型：12void dilate( const Mat&amp; src, Mat&amp; dst, const Mat&amp; element,Point anchor=Point(-1,-1), int iterations=1,int borderType=BORDER_CONSTANT,const Scalar&amp; borderValue=morphologyDefaultBorderValue() );参数：src:原图像。dst：目标图像。element:腐蚀操作的内核。 如果不指定，默认为一个简单的 3x3 矩阵。否则，我们就要明确指定它的形状，可以使用函数getStructuringElement().anchor:默认为Point(-1,-1),内核中心点。省略时为默认值。iterations:腐蚀次数。省略时为默认值1。borderType:推断边缘类型，具体参见borderInterpolate函数。默认为BORDER_DEFAULT，省略时为默认值。borderValue:边缘值，具体可参见createMorphoogyFilter函数。可省略。 二、blur 均值滤波1234567891011121314#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123;Mat srcImage = imread(\"Phone.png\");imshow(\"src\",srcImage);Mat dstImage;blur(srcImage,dstImage,Size(7,7));imshow(\"dst\",dstImage);waitKey(0);&#125; 均值滤波是一种典型的线性滤波算法，主要是利用像素点邻域的像素值来计算像素点的值。其具体方法是首先给出一个滤波模板kernel，该模板将覆盖像素点周围的其他邻域像素点，去掉像素本身，将其邻域像素点相加然后取平均值即为该像素点的新的像素值，这就是均值滤波的本质。函数原型：1void blur(InputArray src, OutputArray dst, Size ksize, Point anchor=Point(-1,-1), int borderType=BORDER_DEFAULT);参数解释：InputArray src: 输入图像OutputArray dst: 输出图像Size ksize: 滤波模板kernel的尺寸，如Size(3,3)Point anchor=Point(-1, -1): 字面意思是锚点，也就是处理的像素位于kernel的什么位置，默认值为(-1, -1)即位于kernel中心点，如果没有特殊需要则不需要更改int borderType=BORDER_DEFAULT: 用于推断图像外部像素的某种边界模式，有默认值BORDER_DEFAULT 三、canny边缘检测12345678910111213141516171819202122232425262728#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123;Mat srcImage = imread(\"Phone.png\");//原图像imshow(\"src\",srcImage);Mat dstImage,edge,grayImage;//创建与srcImage同大小和同类型的矩阵dstImage.create(srcImage.size(),srcImage.type());//转换成灰度图像cvtColor(srcImage,grayImage,COLOR_BGR2GRAY);//使用滤波函数降噪，这里用的是10*10内核blur(grayImage,edge,Size(10,10));//运行canny算子Canny(edge,edge,3,9,3);//目标图像imshow(\"dst\",edge);waitKey(0);&#125; 1.cvtColor颜色空间转换函数函数原型：123456void cvtColor( InputArray src, // 输入图像 OutputArray dst, // 输出图像 int code, // 颜色映射码 int dstCn = 0 // 输出的通道数 (0='automatic') );cvtColor()支持多种颜色空间之间的转换，目前常见的颜色空间均支持，并且在转换的过程中能够保证数据的类型不变，即转换后的图像的数据类型和位深与源图像一致。 2.canny算法Canny边缘检测于1986年由JOHN CANNY首次在论文《A Computational Approach to Edge Detection》中提出，就此拉开了Canny边缘检测算法的序幕。Canny边缘检测是从不同视觉对象中提取有用的结构信息并大大减少要处理的数据量的一种技术，目前已广泛应用于各种计算机视觉系统。函数原型：1234567891011void cv::Canny ( InputArray image,//输入图像，必须为单通道灰度图OutputArray edges,//输出图像，为单通道黑白图double threshold1,double threshold2,//第三个参数和第四个参数表示阈值，这二个阈值中当中的小阈值用来控制边缘连接，大的阈值用来控制强边缘的初始分割，即如果一个像素的梯度大于上限值，则被认为是边缘像素，如果小于下限阈值，则被抛弃。如果该点的梯度在两者之间则当这个点与高于上限值的像素点连接时我们才保留，否则删除。int apertureSize = 3,//第五个参数表示Sobel 算子大小，默认为3即表示一个3*3的矩阵。Sobel 算子与高斯拉普拉斯算子都是常用的边缘算子bool L2gradient = false ) 阈值的大小比最好为2：1或3：1。 测试图像：","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"Mac 使用VS Code 通过cmake 配置 OpenCV和Pytorch C++ API","slug":"Deep-Learning-Starting","date":"2019-03-05T15:16:11.000Z","updated":"2019-03-11T12:36:40.630Z","comments":true,"path":"2019/03/05/Deep-Learning-Starting/","link":"","permalink":"http://yoursite.com/2019/03/05/Deep-Learning-Starting/","excerpt":"前情由于pytorch的1.0正式版发布不久，同时较为稳定的c++的API也是在正式版中提供支持，网上的教程不多，因此可供参考的资料只有官方文档和零零散散的博客。不过由于Mac和Linux本身相差不大，一些Linux的配置教程同样值得参考。以下给出链接：官方文档https://pytorch.org/cppdocs/installing.htmlOldpan的个人博客（特别感谢Oldpan老哥的帖子给我的巨大帮助）：利用Pytorch的C++前端(libtorch)读取预训练权重并进行预测：https://oldpan.me/archives/pytorch-c-libtorch-inferencePytorch源码编译简明指南：https://m.oldpan.me/archives/pytorch-build-simple-instruction","text":"前情由于pytorch的1.0正式版发布不久，同时较为稳定的c++的API也是在正式版中提供支持，网上的教程不多，因此可供参考的资料只有官方文档和零零散散的博客。不过由于Mac和Linux本身相差不大，一些Linux的配置教程同样值得参考。以下给出链接：官方文档https://pytorch.org/cppdocs/installing.htmlOldpan的个人博客（特别感谢Oldpan老哥的帖子给我的巨大帮助）：利用Pytorch的C++前端(libtorch)读取预训练权重并进行预测：https://oldpan.me/archives/pytorch-c-libtorch-inferencePytorch源码编译简明指南：https://m.oldpan.me/archives/pytorch-build-simple-instruction 开始所需安装的工具有：1.VS Code：这个官网下载即可2.OpenCV 4.0.1:终端输入1brew install opencv即可安装3.Pytorch1.0:可参考上面给出的Pytorch源码编译简明指南，首先在终端输入1git clone --recursive https://github.com/pytorch/pytorch获取最新源码，然后通过编译得到Mac可以读取的.dylib文件（注意：在官方文档中下载的libtorch-shared-with-deps-latest.zip文件解压后所得到的文件夹里的动态库文件是以.so结尾，是Linux下的动态库文件，Mac识别不了）编译时应该先进入到刚刚下载好的Pytorch文件夹（默认的路径应该是/Users/用户名/pytorch）下，然后终端执行123mkdir buildcd buildpython ../tools/build_libtorch.py进行libtorch（即c++ API）的编译，时间较长。4.编译好之后打开VS Code新建一个工程，在这里我引用Oldpan老哥的例子 工程名叫simnet，然后在simnet文件夹下新建一个CMakeLists.txt和一个test.cpp（build先不建），CMakeLists.txt中的代码为：123456789101112131415161718192021cmake_minimum_required(VERSION 3.12 FATAL_ERROR)project(simnet)find_package(Torch REQUIRED) # 查找libtorchfind_package(OpenCV REQUIRED) # 查找OpenCVif(NOT Torch_FOUND)message(FATAL_ERROR \"Pytorch Not Found!\")endif(NOT Torch_FOUND)message(STATUS \"Pytorch status:\")message(STATUS \" libraries: $&#123;TORCH_LIBRARIES&#125;\")message(STATUS \"OpenCV library status:\")message(STATUS \" version: $&#123;OpenCV_VERSION&#125;\")message(STATUS \" libraries: $&#123;OpenCV_LIBS&#125;\")message(STATUS \" include path: $&#123;OpenCV_INCLUDE_DIRS&#125;\")add_executable(simnet test.cpp)target_link_libraries(simnet $&#123;TORCH_LIBRARIES&#125; $&#123;OpenCV_LIBS&#125;) set_property(TARGET simnet PROPERTY CXX_STANDARD 11) test.cpp中的代码为：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include &lt;opencv2/opencv.hpp&gt;#include \"torch/script.h\"#include \"torch/torch.h\"#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std;// resize并保持图像比例不变cv::Mat resize_with_ratio(cv::Mat&amp; img) &#123;cv::Mat temImage;int w = img.cols;int h = img.rows;float t = 1.;float len = t * std::max(w, h);int dst_w = 224, dst_h = 224;cv::Mat image = cv::Mat(cv::Size(dst_w, dst_h), CV_8UC3, cv::Scalar(128,128,128));cv::Mat imageROI;if(len==w)&#123;float ratio = (float)h/(float)w;cv::resize(img,temImage,cv::Size(224,224*ratio),0,0,cv::INTER_LINEAR);imageROI = image(cv::Rect(0, ((dst_h-224*ratio)/2), temImage.cols, temImage.rows));temImage.copyTo(imageROI);&#125;else&#123;float ratio = (float)w/(float)h;cv::resize(img,temImage,cv::Size(224*ratio,224),0,0,cv::INTER_LINEAR);imageROI = image(cv::Rect(((dst_w-224*ratio)/2), 0, temImage.cols, temImage.rows));temImage.copyTo(imageROI);&#125;return image;&#125;int main(int argc, const char* argv[])&#123;if (argc != 2) &#123;std::cerr &lt;&lt; \"usage: example-app &lt;path-to-exported-script-module&gt;\\n\";return -1;&#125;cv::VideoCapture stream(0);cv::namedWindow(\"Gesture Detect\", cv::WINDOW_AUTOSIZE);std::shared_ptr&lt;torch::jit::script::Module&gt; module = torch::jit::load(argv[1]);module-&gt;to(at::kCUDA);cv::Mat frame;cv::Mat image;cv::Mat input;while(1)&#123;stream&gt;&gt;frame;image = resize_with_ratio(frame);imshow(\"resized image\",image); //显示摄像头的数据cv::cvtColor(image, input, cv::COLOR_BGR2RGB);// 下方的代码即将图像转化为Tensor，随后导入模型进行预测torch::Tensor tensor_image = torch::from_blob(input.data, &#123;1,input.rows, input.cols,3&#125;, torch::kByte);tensor_image = tensor_image.permute(&#123;0,3,1,2&#125;);tensor_image = tensor_image.toType(torch::kFloat);tensor_image = tensor_image.div(255);tensor_image = tensor_image.to(torch::kCUDA);torch::Tensor result = module-&gt;forward(&#123;tensor_image&#125;).toTensor();auto max_result = result.max(1, true);auto max_index = std::get&lt;1&gt;(max_result).item&lt;float&gt;();if(max_index == 0)cv::putText(frame, \"paper\", &#123;40, 50&#125;, cv::FONT_HERSHEY_PLAIN, 2.0, cv::Scalar(0, 255, 0), 2);else if(max_index == 1)cv::putText(frame, \"scissors\", &#123;40, 50&#125;, cv::FONT_HERSHEY_PLAIN, 2.0, cv::Scalar(0, 255, 0), 2);elsecv::putText(frame, \"stone\", &#123;40, 50&#125;, cv::FONT_HERSHEY_PLAIN, 2.0, cv::Scalar(0, 255, 0), 2);imshow(\"Gesture Detect\",frame); //显示摄像头的数据cv::waitKey(30);&#125; 保存。 5.终端cd进入simnet工程文件夹，然后执行1234mkdir buildcd buildcmake -DCMAKE_PREFIX_PATH=/absolute/path/to/pytorch ..make其中/absolute/path/to/pytorch是pytorch文件夹的绝对路径，一般是/Users/用户名/pytorch这样就编译完成了可以执行1./simnet来运行你的工程了！ 后记由于这是我第一次写教程，很多地方可能有所疏漏，并且配置的过程中踩了无数的坑，可能很多地方起了效果但是我根本没有注意到，还有前期的一些准备工作我也没有提及（比如说anaconda的安装，pip、conda、brew的安装和更新），这些网上有很多大佬写的非常详尽的教程，大家可以多多参考，我这里只是提供了一个自己的思路，如果没有安装成功还望见谅！","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/categories/Deep-Learning/"}],"tags":[]},{"title":"《La La Land》：有关闪耀而易碎的、遗憾而完美的那些事","slug":"Land","date":"2019-01-21T10:41:25.000Z","updated":"2019-01-21T15:11:33.956Z","comments":true,"path":"2019/01/21/Land/","link":"","permalink":"http://yoursite.com/2019/01/21/Land/","excerpt":"City of stars, are you shining for me?","text":"City of stars, are you shining for me? LA，los angeles，city of stars，确实太过闪耀，有太多人，哪怕从未踏上洛杉矶的土地，也对那里根种了太多美好的幻想。我想起几年前我拿着我新买的PS4，打开《GTA V》的时候，我的天！主角Michael的家外边就是粼粼的海面和充满“热情”的沙滩，无云而湛蓝的天际延伸至远处渐渐变淡，与海面交融直至分不清楚。坐上红色跑车，手搭在车窗上，沿着海岸线一路向北，深红色的岩石蒸腾着热气，视线延伸向上看见绿色————是棕榈树————阳光刺眼，模模糊糊，看不真切；渐入钢铁丛林，阳光也是热辣的吓人，大片大片的反光，大片大片的明媚，西装革履的男人，潮流青年，穿休闲服遛狗的人，酒鬼，或昂首挺胸，或散散漫漫，或失魂落魄，穿梭在层层叠叠的阴影和光斑之间，完美融进这这城市里，一如他们迥然的处境和各不相同的命运。也许是Rockstar太过顶级的美工，又有可能是他们早年的作品圣安第列斯已经满足了我的杀戮欲望，现在我规规矩矩地在马路上开着我的车，老老实实的等着红灯熄灭，绿灯闪烁，循规蹈矩的和其他市民一般驾驶。再往上开，房子渐渐的又变矮了，地势升高，一块巨大的标牌从山顶慢慢向我挪来。我慢慢驶近，在不经意间，它突然变得明亮起来。 啊，HOLLY WOOD。 闪亮的灯牌提醒我天色已晚。我下了车，站在富人区的山顶上，眺望着整个圣洛都。细小闪耀的灯光如同沙粒，连着川流不息的车流，成了江成了河，向我诉说这座钢之巨人自他从这片泥土地里诞生起便永不入睡。是啊，它是如此勤奋地活着，连同它身体里的人们，仿佛都是永不入睡的，为了梦想，为了家庭，为了生活，抑或是吸了毒嗨了药，who cares？圣洛都的天空，是我见过的最美的天空————渐变色的，难以形容————或者可以想象一下，你现在正在一个晚宴上，和你心仪的人交谈，总有那么一两个时候你会觉得羞涩，心里有头小鹿撞来撞去，眼神不知道该往哪里看；于是你只好低头盯着你手里拿着的酒杯，因为这样显得你优雅而有礼貌，你开始端详葡萄酒的颜色：深红的葡萄酒被晚宴上昏暗的光线一打，自底向上由浅入深，不断的变换着色彩，可能是浅粉色，可能是淡蓝色，可能是深紫色；你挪动酒杯，颜色也跟着变化————是了，这就是LA的夜空，不仅仅是渐变的，柔和的，绚丽的，同时，它也是暧昧的，易碎的，不可告人的。 后来我打通了游戏，我最后一次看着Michael，Franklin，Trevor站在一起，看着车子渐渐沉进海底，三个人各自说着像总结一样的话，仿佛是隔着屏幕告诉我们他们的故事到这里就结束了，从今往后他们三个再在哪里相见，以什么样的方式相见，都不再关我的事，自北扬克顿拉开帷幕的故事到这里收场，生活还要继续；后来，因为学习，我（被强迫）收起了我的PS4，到那个时候我已经能轻车熟路的开遍圣洛都的大街小巷，我已然成为了一个老圣洛都人；可是那一晚，我打开我新买的PS4，打开我新买的《GTA V》，逛了逛海滩，坐上我的红色跑车，一路向北……那一幕幕带给我的震撼，我将永远不会忘记。因为是从那个时候起，我真正地将游戏打心底里视为一种艺术，而不是什么害人的消遣，到后来，我从网上知道原来GTA系列是描述美国梦的，我总是不由自主地和那个夜晚联系在一起——繁华的，易碎的，暧昧的，不可告人的……大概就是这样的吧。 我写了这么长的铺垫，其实是想告诉你，为什么我会对这部电影感触如此之深：不仅仅是因为我再次看到了那些似曾相识的场景，美丽的难以忘怀；而且我还看到了另一个故事，有关美国梦的故事，美好的令人心碎。一如这部电影的画面，我明知现实生活中不可能发生这样的故事，却根本不愿意去质疑。就让我带着迷蒙的的眼神，盯着那只葡萄酒杯；就让我微醺的脸色，更浓一分吧。 就当我做了一个梦，而我选择再不复醒。 还没写完先放放。","categories":[{"name":"Film Comment","slug":"Film-Comment","permalink":"http://yoursite.com/categories/Film-Comment/"}],"tags":[]}]}