{"meta":{"title":"Caesar Bao's blogs","subtitle":null,"description":"Someone becomes silent for getting more people hear his voice.","author":"Caesar Bao","url":"http://yoursite.com"},"pages":[{"title":"categories","date":"2019-01-20T10:22:15.000Z","updated":"2019-01-20T10:23:02.910Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"search","date":"2019-01-20T10:23:56.000Z","updated":"2019-01-20T10:24:19.893Z","comments":true,"path":"search/index.html","permalink":"http://yoursite.com/search/index.html","excerpt":"","text":""}],"posts":[{"title":"warpAffine()函数实现最小外接矩形和原始图像平行","slug":"OpenCV-Learning-Day-16","date":"2019-03-26T12:26:09.000Z","updated":"2019-03-26T13:41:36.338Z","comments":true,"path":"2019/03/26/OpenCV-Learning-Day-16/","link":"","permalink":"http://yoursite.com/2019/03/26/OpenCV-Learning-Day-16/","excerpt":"前言：本来今天想一并吧图像的旋转和裁剪给一起完成了，但是图像在旋转之后的坐标定位一直有问题，所以今天只好放出在昨天的博客的基础上做的图像旋转的函数，旋转之后目标图像的最小外接矩形是和原始图像平行的，为的是设置ROI为裁剪图像做准备。","text":"前言：本来今天想一并吧图像的旋转和裁剪给一起完成了，但是图像在旋转之后的坐标定位一直有问题，所以今天只好放出在昨天的博客的基础上做的图像旋转的函数，旋转之后目标图像的最小外接矩形是和原始图像平行的，为的是设置ROI为裁剪图像做准备。 测试代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;cmath&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;using namespace std;using namespace cv;float angle;Point pointlu;void minRect(Mat&amp; srcImage);void Rotate(Mat &amp;src,Mat &amp;dst,float angle);static inline bool ContoursSortFunction(vector&lt;Point&gt; contour1,vector&lt;Point&gt; contour2);int main()&#123; string path = \"/Users/cezarbao/Desktop/TestImages/*.bmp\"; vector&lt;Mat&gt;images; vector&lt;String&gt;srcImages; glob(path,srcImages,false); size_t cnt = srcImages.size(); for(int i = 0; i &lt; cnt; i++) &#123; images.push_back(imread(srcImages[i])); minRect(images[i]); Rotate(images[i],images[i],angle); imshow(\"image\",images[i]); waitKey(0); &#125;&#125;void minRect(Mat&amp; srcImg)&#123; Mat dstImage = srcImg.clone(); cvtColor(dstImage, dstImage, COLOR_BGR2GRAY); threshold(dstImage, dstImage, 254, 255, THRESH_BINARY); //imshow(\"srcImage\", dstImage); vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarcy; findContours(dstImage, contours, hierarcy, RETR_LIST, CHAIN_APPROX_NONE); sort(contours.begin(),contours.end(),ContoursSortFunction); contours.erase(contours.begin()); vector&lt;RotatedRect&gt; box(contours.size()); //定义最小外接矩形集合 Point2f rect[4]; for(int i=0; i &lt; 1; i++) &#123; box[i] = minAreaRect(Mat(contours[i])); //计算每个轮廓最小外接矩形 box[i].points(rect); //把最小外接矩形四个端点复制给rect数组 angle = box[i].angle; for(int j=0; j&lt;4; j++) &#123; line(srcImg, rect[j], rect[(j+1)%4], Scalar(0, 0, 255)); //绘制最小外接矩形每条边 &#125; &#125;&#125;static inline bool ContoursSortFunction(vector&lt;Point&gt; contour1,vector&lt;Point&gt; contour2)&#123; return (contourArea(contour1) &gt; contourArea(contour2));&#125;void Rotate(Mat &amp;src,Mat &amp;dst,float angle)&#123; //fill int maxBorder =(int) (max(src.cols, src.rows)* 1.414); //即为sqrt(2)*max int dx = (maxBorder - src.cols)/2; int dy = (maxBorder - src.rows)/2; copyMakeBorder(src, dst, dy, dy, dx, dx, BORDER_CONSTANT,Scalar(0,0,0)); //rotate Point2f center( (float)(dst.cols/2) , (float) (dst.rows/2)); Mat affine_matrix = getRotationMatrix2D( center, angle, 1.0 );//求得旋转矩阵 warpAffine(dst, dst, affine_matrix, dst.size());&#125; 一、copyMakeBorder()边缘扩充函数函数原型：12345void copyMakeBorder( const Mat&amp; src, Mat&amp; dst, int top, int bottom, int left, int right, int borderType, const Scalar&amp; value=Scalar())第一个参数和第二个参数分别是输入图像和输出图像top、bottom、left、right参数非常明显，分别是顶端、底部、左边和右边所需填充的距离borderType：扩充边缘的类型，就是外插的类型，OpenCV中给出以下几种方式BORDER_REPLICATE 对边界像素进行复制BORDER_REFLECT 对感兴趣的图像中的像素在两边分别进行复制，也就是左右各复制一次BORDER_REFLECT_101 只复制一次，左右各占一半BORDER_WRAP 外包装（？）BORDER_CONSTANT 常量，选择这种方式的时候，需要用到最后一个参数为扩充的边缘选择颜色 二、warpAffine()旋转函数函数原型：123456789void warpAffine( InputArray src, OutputArray dst, InputArray M, Size dsize, int flags = INTER_LINEAR, int borderMode = BORDER_CONSTANT, const Scalar &amp; borderValue = Scalar() )src: 输入图像dst: 输出图像，尺寸由dsize指定，图像类型与原图像一致M: 2X3的变换矩阵dsize: 指定图像输出尺寸flags: 插值算法标识符，有默认值INTER_LINEARborderMode: 边界像素模式，有默认值BORDER_CONSTANTborderValue: 边界取值，有默认值Scalar()即0 三、getRotationMatrix2D()旋转图像矩阵取得函数warpAffine()函数的InputArrey M的取得需要用到这个函数函数原型：12345Mat getRotationMatrix2D( Point2f center, double angle, double scale)center: Point2f类型，表示原图像的旋转中心angle: double类型，表示图像旋转角度，角度为正则表示逆时针旋转，角度为负表示逆时针旋转（坐标原点是图像左上角）scale: 缩放系数","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"最小外接矩形（不完美）","slug":"OpenCV-Learning-Day-15","date":"2019-03-25T13:56:14.000Z","updated":"2019-03-26T02:53:30.354Z","comments":true,"path":"2019/03/25/OpenCV-Learning-Day-15/","link":"","permalink":"http://yoursite.com/2019/03/25/OpenCV-Learning-Day-15/","excerpt":"前言：本章节结合前面一章的批处理函数glob()，进行图像的最小外接矩形的描绘（实际效果不太完美）。","text":"前言：本章节结合前面一章的批处理函数glob()，进行图像的最小外接矩形的描绘（实际效果不太完美）。 测试代码：12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;using namespace std;using namespace cv;void minRect(Mat&amp; srcImage);int main()&#123; string path = \"/Users/cezarbao/Desktop/DeepLearning/OpenCV/*.jpeg\"; vector&lt;Mat&gt;images; vector&lt;String&gt;srcImages; glob(path,srcImages,false); size_t cnt = srcImages.size(); for(int i = 0; i &lt; cnt; i++) &#123; images.push_back(imread(srcImages[i])); minRect(images[i]); &#125;&#125;void minRect(Mat&amp; srcImg)&#123; Mat dstImage = srcImg.clone(); cvtColor(srcImg, srcImg, COLOR_BGR2GRAY); threshold(srcImg, srcImg, 100, 255, THRESH_BINARY); vector&lt;vector&lt;Point&gt;&gt; contours; vector&lt;Vec4i&gt; hierarcy; findContours(srcImg, contours, hierarcy, RETR_EXTERNAL, CHAIN_APPROX_NONE); vector&lt;RotatedRect&gt; box(contours.size()); //定义最小外接矩形集合 Point2f rect[4]; for(int i=0; i&lt;contours.size(); i++) &#123; box[i] = minAreaRect(Mat(contours[i])); //计算每个轮廓最小外接矩形 box[i].points(rect); //把最小外接矩形四个端点复制给rect数组 for(int j=0; j&lt;4; j++) &#123; line(dstImage, rect[j], rect[(j+1)%4], Scalar(0, 0, 255), 2, LINE_AA); //绘制最小外接矩形每条边 &#125; &#125; imshow(\"Image\",dstImage); waitKey(0);&#125;效果图：（可以看到第二张图明显识别出了问题……） 一、findContours()轮廓扫描函数函数原型：12345678findContours( InputOutputArray image, OutputArrayOfArrays contours, OutputArray hierarchy, int mode, int method, Point offset=Point())第一个参数是输入图像，这里有很大一个坑，输入图像必须是八位单通道图像（即8UC1），在函数中被认为是一个二值化图像（即所有非零元素都被视作是相等的，非0即1），但如果mode是CV_RETR_CCOMP 或者 CV_RETR_FLOODFILL，输入图像也可以是32位的整型图像(CV_32SC1)。第二个参数是二维vector数组，这里将使用找到的轮廓的列表进行填充（即，这将是一个contours的vector,其中contours[i]表示一个特定的轮廓，这样，contours[i][j]将表示contour[i]的一个特定的端点）。第三个参数可以指定，也可以不提指定。如果指定的话，输出hierarchy，将会描述输出轮廓树的结构信息。（Vec4i是Vec&lt;int,4&gt;的别名，定义了一个“向量内每一个元素包含了4个int型变量”的向量）第四个参数将会告诉OpenCV你想用何种方式来对轮廓进行提取RETR_EXTERNAL：表示只提取最外面的轮廓；RETR_LIST：表示提取所有轮廓并将其放入列表；RETR_CCOMP:表示提取所有轮廓并将组织成一个两层结构，其中顶层轮廓是外部轮廓，第二层轮廓是“洞”的轮廓；RETR_TREE：表示提取所有轮廓并组织成轮廓嵌套的完整层级结构。第五个参数给出轮廓如何呈现的方法CHAIN_APPROX_NONE：将轮廓中的所有点的编码转换成点；CHAIN_APPROX_SIMPLE：压缩水平、垂直和对角直线段，仅保留它们的端点； CHAIN_APPROX_TC89_L1 or CHAIN_APPROX_TC89_KCOS：应用Teh-Chin链近似算法中的一种风格 二、minAreaRect()函数函数原型：1RotatedRect minAreaRect(InputArray points)第一个参数可以输入点阵容器（vector）或者Mat类型的图像，这里很坑的是，如果参数是Mat类型必须满足depth == CV_32F || depth == CV_32S，且checkVector(2)才可以，否则会报错（minAreaRect()中主要调用的求凸包的函数convexHull()会检查Mat满不满足上面的条件）。Mat::depth()函数：求矩阵中元素的一个通道的数据类型，这个值和type是相关的。Mat::checkVector()函数：当Mat的channels,depth,和连续性 满足checkVector的参数内容时,返回(int)(total()*channels()/_elemChannels), 否则返回-1。checkVector(2)，要求矩阵的列数位2。（我就是因为minAreaRect()中的Mat类总是报错才怒转findContours()函数的，然而测试代码的视线效果并不完美，有待改进） 三、RotatedRect类RotatedRect类常用于配合minAreaRect()函数的计算（因为minAreaRect()函数的返回类型就是RotatedRect类）函数定义：1234567891011121314151617class CV_EXPORTS RotatedRect&#123; public: //! various constructors RotatedRect(); RotatedRect(const Point2f&amp; center, const Size2f&amp; size, float angle); RotatedRect(const CvBox2D&amp; box); //! returns 4 vertices of the rectangle void points(Point2f pts[]) const; //! returns the minimal up-right rectangle containing the rotated rectangle Rect boundingRect() const; //! conversion to the old-style CvBox2D structure operator CvBox2D() const; Point2f center; //&lt; the rectangle mass center Size2f size; //&lt; width and height of the rectangle float angle; //&lt; the rotation angle. When the angle is 0, 90, 180, 270 etc., the rectangle becomes an up-right rectangle.&#125;;RotatedRect类中定义了矩形的中心点center、尺寸size（包括width、height）、旋转角度angle共3个成员变量；points()函数用于求矩形的4个顶点，boundingRect()函数求包含最小外接矩形的，与坐标轴平行（或垂直）的最小矩形。参考博文：OpenCV 中boundingRect、minAreaRect的用法区别blog.csdn.net/u013925378/article/details/84563011Opencv轮廓检测findContours分析（层次结构）www.jianshu.com/p/4bc3349b4611【OpenCV3】图像轮廓查找与绘制——cv::findContours()与cv::drawContours()详解blog.csdn.net/guduruyu/article/details/69220296Opencv RotatedRect类中的points、angle、width、height等详解blog.csdn.net/mailzst1/article/details/83141632","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"批处理函数和二值化函数","slug":"OpenCV-Learning-Day-14","date":"2019-03-24T12:45:28.000Z","updated":"2019-03-26T02:53:08.435Z","comments":true,"path":"2019/03/24/OpenCV-Learning-Day-14/","link":"","permalink":"http://yoursite.com/2019/03/24/OpenCV-Learning-Day-14/","excerpt":"前言：图像批处理，管进不管出。","text":"前言：图像批处理，管进不管出。 测试代码：1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;time.h&gt;#include &lt;string&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;using namespace std;using namespace cv;int main()&#123; string path = \"/Users/cezarbao/Desktop/TestImages/*.bmp\"; vector&lt;Mat&gt;images; vector&lt;String&gt;srcImages; glob(path,srcImages,false); size_t cnt = srcImages.size(); for(int i = 0; i &lt; cnt; i++) &#123; images.push_back(imread(srcImages[i])); //cvtColor(images[i],images[i],COLOR_BGR2GRAY); //blur(images[i],images[i],Size(5,5)); threshold(images[i],images[i],170,255,THRESH_BINARY); imshow(\"Image\",images[i]); waitKey(0); &#125;&#125; 一、glob()批处理函数glob()函数可以批处理指定文件夹中的图像，函数目的是将pattern路径下的所用文件名存进&amp;result中函数原型：1void glob(String pattern, vector&lt;String&gt; &amp;result, bool recursive = false)第一个参数是文件夹的绝对路径第二个参数是存放图片名称和路径的vector容器，需要注意的是该容器必须是OpenCV的String类第三个参数默认是false，当recursive为false时，仅仅遍历指定文件夹内符合模式的文件，当recursive为true时，会同时遍历指定文件夹的子文件夹 二、threshold()二值化函数函数原型：1234567double threshold( InputArray src, OutputArray dst, double thresh, double maxval, int type)第一个参数和第二个参数分别为输入图像和输出图像thresh参数表示阈值maxval参数表示与THRESH_BINARY和THRESH_BINARY_INV阈值类型一起使用设置的最大值。type参数表示阈值类型：12345type=CV_THRESH_BINARY //如果 src(x,y)&gt;threshold ,dst(x,y) = max_value; 否则,dst（x,y）=0;type=CV_THRESH_BINARY_INV //如果 src(x,y)&gt;threshold,dst(x,y) = 0; 否则,dst(x,y) = max_value.type=CV_THRESH_TRUNC //如果 src(x,y)&gt;threshold，dst(x,y) = max_value; 否则dst(x,y) = src(x,y).type=CV_THRESH_TOZERO //如果src(x,y)&gt;threshold，dst(x,y) = src(x,y) ; 否则 dst(x,y) = 0。type=CV_THRESH_TOZERO_INV //如果 src(x,y)&gt;threshold，dst(x,y) = 0 ; 否则dst(x,y) = src(x,y)","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"离散傅里叶变换函数的补充","slug":"OpenCV-Learning-Day-13","date":"2019-03-23T13:30:58.000Z","updated":"2019-03-26T02:52:44.636Z","comments":true,"path":"2019/03/23/OpenCV-Learning-Day-13/","link":"","permalink":"http://yoursite.com/2019/03/23/OpenCV-Learning-Day-13/","excerpt":"前言：我的上一篇的博客的关于傅里叶变换的一些函数补充，理解不易，且行且珍惜～","text":"前言：我的上一篇的博客的关于傅里叶变换的一些函数补充，理解不易，且行且珍惜～ 测试代码在上一篇。原图：测试图； 一、getOptimalDFTSize()函数返回给定向量尺寸经过DFT变换后结果的最优尺寸大小。其函数定义：1int getOptimalDFTSize(int vecsize)int vecsize: 输入向量尺寸大小(vector size)DFT变换在一个向量尺寸上不是一个单调函数，当计算两个数组卷积或对一个数组进行光学分析，它常常会用0扩充一些数组来得到稍微大点的数组以达到比原来数组计算更快的目的。一个尺寸是2阶指数（2,4,8,16,32……）的数组计算速度最快，一个数组尺寸是2、3、5的倍数（例如：300 = 5*5*3*2*2）同样有很高的处理效率。getOptimalDFTSize()函数返回大于或等于vecsize的最小数值N，这样尺寸为N的向量进行DFT变换能得到更高的处理效率。在当前N通过p，q，r等一些整数得出N = 2^p*3^q*5^r.这个函数不能直接用于DCT（离散余弦变换）最优尺寸的估计，可以通过getOptimalDFTSize((vecsize+1)/2)*2得到。 二、magnitude()函数函数原型：1void magnitude(InputArray x, InputArray y, OutputArray magnitude)InputArray x: 浮点型数组的x坐标矢量，也就是实部InputArray y: 浮点型数组的y坐标矢量，必须和x尺寸相同OutputArray magnitude: 与x类型和尺寸相同的输出数组 三、copyMakeBorder()扩充图像边界，其函数定义如下：12345678910void copyMakeBorder( InputArray src, OutputArray dst, int top, int bottom, int left, int right, int borderType, const Scalar&amp; value=Scalar())InputArray src: 输入图像OutputArray dst: 输出图像，与src图像有相同的类型，其尺寸应为Size(src.cols+left+right, src.rows+top+bottom)int类型的top、bottom、left、right: 在图像的四个方向上扩充像素的值int borderType: 边界类型，由borderInterpolate()来定义，常见的取值为BORDER_CONSTANTconst Scalar&amp; value = Scalar(): 如果边界类型为BORDER_CONSTANT则表示为边界值 四、normalize() 函数归一化就是把要处理的数据经过某种算法的处理限制在所需要的范围内。首先归一化是为了后面数据处理的方便，其次归一化能够保证程序运行时收敛加快。归一化的具体作用是归纳同意样本的统计分布性，归一化在0-1之间是统计的概率分布，归一化在某个区间上是统计的坐标分布，在机器学习算法的数据预处理阶段，归一化也是非常重要的步骤。123456789void normalize( InputArray src, OutputArray dst, double alpha=1, double beta=0, int norm_type=NORM_L2, int dtype=-1, InputArray mask=noArray())InputArray src: 输入图像OutputArray dst: 输出图像，尺寸大小和src相同double alpha = 1: range normalization模式的最小值double beta = 0: range normalization模式的最大值，不用于norm normalization(范数归一化)模式int norm_type = NORM_L2: 归一化的类型，主要有 NORM_INF: 归一化数组的C-范数（绝对值的最大值）NORM_L1: 归一化数组的L1-范数（绝对值的和）NORM_L2: 归一化数组的L2-范数（欧几里得）NORM_MINMAX: 数组的数值被平移或缩放到一个指定的范围，线性归一化，一般较常用。int dtype = -1: 当该参数为负数时，输出数组的类型与输入数组的类型相同，否则输出数组与输入数组只是通道数相同，而depth = CV_MAT_DEPTH(dtype)InputArray mask = noArray(): 操作掩膜版，用于指示函数是否仅仅对指定的元素进行操作。","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"离散傅里叶变换","slug":"OpenCV-Learning-Day-12","date":"2019-03-22T12:26:13.000Z","updated":"2019-03-26T02:16:24.251Z","comments":true,"path":"2019/03/22/OpenCV-Learning-Day-12/","link":"","permalink":"http://yoursite.com/2019/03/22/OpenCV-Learning-Day-12/","excerpt":"前言：本节学习离散傅里叶变换，好难啊～分两天学习","text":"前言：本节学习离散傅里叶变换，好难啊～分两天学习 测试代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;#include &lt;time.h&gt;#include &lt;string&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;using namespace std;using namespace cv;int main()&#123; Mat srcIamge = imread(\"3.jpg\",0); if(!srcIamge.data)&#123; printf(\"Failed!\"); return 0; &#125; imshow(\"srcImage\",srcIamge); int m = getOptimalDFTSize(srcIamge.rows); int n = getOptimalDFTSize(srcIamge.cols); Mat padded; copyMakeBorder(srcIamge,padded,0,m - srcIamge.rows,0,n - srcIamge.cols,BORDER_CONSTANT,Scalar::all(0)); Mat planes[] = &#123;Mat_&lt;float&gt;(padded),Mat::zeros(padded.size(),CV_32F)&#125;; Mat complexI; merge(planes,2,complexI); dft(complexI,complexI); split(complexI,planes); magnitude(planes[0],planes[1],planes[0]); Mat magnitudeImage = planes[0]; magnitudeImage = magnitudeImage(Rect(0,0,magnitudeImage.cols &amp; -2,magnitudeImage.rows &amp; -2)); int cx = magnitudeImage.cols / 2; int cy = magnitudeImage.rows / 2; Mat q0(magnitudeImage, Rect(0,0,cx,cy)); Mat q1(magnitudeImage, Rect(cx,0,cx,cy)); Mat q2(magnitudeImage, Rect(0,cy,cx,cy)); Mat q3(magnitudeImage, Rect(cx,cy,cx,cy)); Mat tmp; q0.copyTo(tmp); q3.copyTo(q0); tmp.copyTo(q3); q1.copyTo(tmp); q2.copyTo(q1); tmp.copyTo(q2); normalize(magnitudeImage,magnitudeImage,0,1,NORM_MINMAX); imshow(\"dstImage\",magnitudeImage); waitKey(); return 0;&#125; 一：dft()函数参数解释：第一个参数为输入图像，可以是实数或虚数第二个参数为输出图像，其大小和类型取决于第三个参数flags第三个参数为转换的标识符，有默认值0.其可取的值如下所示：DFT_INVERSE: 用一维或二维逆变换取代默认的正向变换DFT_SCALE: 缩放比例标识符，根据数据元素个数平均求出其缩放结果，如有N个元素，则输出结果以1/N缩放输出，常与DFT_INVERSE搭配使用。DFT_ROWS: 对输入矩阵的每行进行正向或反向的傅里叶变换；此标识符可在处理多种适量的的时候用于减小资源的开销，这些处理常常是三维或高维变换等复杂操作。DFT_COMPLEX_OUTPUT: 对一维或二维的实数数组进行正向变换，这样的结果虽然是复数阵列，但拥有复数的共轭对称性（CCS），可以以一个和原数组尺寸大小相同的实数数组进行填充，这是最快的选择也是函数默认的方法。你可能想要得到一个全尺寸的复数数组（像简单光谱分析等等），通过设置标志位可以使函数生成一个全尺寸的复数输出数组。DFT_REAL_OUTPUT: 对一维二维复数数组进行逆向变换，这样的结果通常是一个尺寸相同的复数矩阵，但是如果输入矩阵有复数的共轭对称性（比如是一个带有DFT_COMPLEX_OUTPUT标识符的正变换结果），便会输出实数矩阵。int nonzeroRows = 0: 当这个参数不为0，函数会假设只有输入数组（没有设置DFT_INVERSE）的第一行或第一个输出数组（设置了DFT_INVERSE）包含非零值。这样的话函数就可以对其他的行进行更高效的处理节省一些时间，这项技术尤其是在采用DFT计算矩阵卷积时非常有效。","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"亮度和对比度调节","slug":"OpenCV-Learning-Day-11","date":"2019-03-21T07:01:34.000Z","updated":"2019-03-26T02:51:43.848Z","comments":true,"path":"2019/03/21/OpenCV-Learning-Day-11/","link":"","permalink":"http://yoursite.com/2019/03/21/OpenCV-Learning-Day-11/","excerpt":"前言：本文主要介","text":"前言：本文主要介 测试代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;#include &lt;time.h&gt;#include &lt;string&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;using namespace std;using namespace cv;static void on_ContrastAndBright(int, void*);static void ShowHelpText();int g_nContrastValue;int g_nBrightValue;Mat g_srcImage, g_dstImage;int main()&#123; g_srcImage = imread(\"1.jpg\"); if(!g_srcImage.data)&#123; printf(\"Failed\\n\"); return -1; &#125; g_dstImage = Mat::zeros(g_srcImage.size(), g_srcImage.type()); g_nContrastValue = 80; g_nBrightValue = 80; namedWindow(\"Output\",WINDOW_AUTOSIZE); createTrackbar(\"Contrast:\",\"Output\",&amp;g_nContrastValue,300,on_ContrastAndBright); createTrackbar(\"Bright:\",\"Output\",&amp;g_nBrightValue,200,on_ContrastAndBright); on_ContrastAndBright(g_nContrastValue,0); on_ContrastAndBright(g_nBrightValue,0); while(char(waitKey(1)) != 'q') &#123;&#125; return 0; &#125;static void on_ContrastAndBright(int, void*)&#123; namedWindow(\"Input\",WINDOW_AUTOSIZE); for(int y = 0; y &lt; g_srcImage.rows; y++) &#123; for(int x = 0; x &lt; g_srcImage.cols; x++)&#123; for(int c = 0; c &lt; 3; c++)&#123; g_dstImage.at&lt;Vec3b&gt;(y,x)[c] = saturate_cast&lt;uchar&gt; ((g_nContrastValue*0.01) * (g_srcImage.at&lt;Vec3b&gt;(y,x)[c]) + g_nBrightValue); &#125; &#125; &#125; imshow(\"Input\",g_srcImage); imshow(\"Output\",g_dstImage);&#125;原图：测试图；感觉图片上的时间硬是调早了两个小时…… 1.Mat::zeros()和Mat::ones()Mat::zeros()相当于创建了一张全黑的图，图像矩阵上每个像素点的每个通道全设置为0。Mat::ones()则是将图像矩阵上每个像素点的第一个通道设置为1，其余通道设置为0。 2.saturate_cast防止数据溢出原理如下：12if(data&lt;0) data=0;else if(data&gt;255) data=255; 3.Mat类中的at函数在测试代码中，函数实现亮度和对比度的调节是通过Mat类中的at函数遍历各个像素点并修改来实现的，但这不是最有效率的做法，在测试图像素为4000✖1900左右，在调节亮度和对比度时就会变得非常卡了。还有一种指针的做法和一种迭代器的做法，可以参考我之前的博客。","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"图像通道的分离与合并","slug":"OpenCV-Learning-Day-10","date":"2019-03-20T07:13:13.000Z","updated":"2019-03-26T02:22:00.003Z","comments":true,"path":"2019/03/20/OpenCV-Learning-Day-10/","link":"","permalink":"http://yoursite.com/2019/03/20/OpenCV-Learning-Day-10/","excerpt":"前言不要问，就是水，前言说没就会没。","text":"前言不要问，就是水，前言说没就会没。 一、通道的分离（split()函数）和合并（merge()函数）测试代码：1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;time.h&gt;#include &lt;string&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;using namespace std;using namespace cv;int main()&#123; Mat srcImage = imread(\"2.jpg\"); Mat ImageBlue, ImageGreen, ImageRed; Mat mergeImage; vector&lt;Mat&gt;channels; split(srcImage,channels); ImageBlue = channels.at(0); imshow(\"Blue Channel\",ImageBlue); ImageGreen = channels.at(1); imshow(\"Green Channel\",ImageGreen); ImageRed = channels.at(2); imshow(\"Red Channel\",ImageRed); merge(channels,mergeImage); imshow(\"mergeImage\",mergeImage); waitKey(0);&#125;效果图：蓝色通道：绿色通道：红色通道：合并通道： 1.split()函数：图像通道的分离函数原型：1void split(InputArray m, OutputArrayOfArrays mv)第一个参数为输入图像第二个参数是函数的输出数组或者vector容器 2.merge()函数：图像通道的合并函数原型：1void merge(InputArrayOfArrays mv, OutputArray dst)可以看出merge的两个参数和split函数正好相反：第一个参数是保存函数通道的数组或者vector容器第二个参数为输出图像","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"通过访问图像像素减少图像颜色数量","slug":"OpenCV-Learning-Day-9","date":"2019-03-19T10:54:55.000Z","updated":"2019-03-26T02:51:12.578Z","comments":true,"path":"2019/03/19/OpenCV-Learning-Day-9/","link":"","permalink":"http://yoursite.com/2019/03/19/OpenCV-Learning-Day-9/","excerpt":"前言：由于你可以自己看下面的内容，所以没有前言。","text":"前言：由于你可以自己看下面的内容，所以没有前言。 该测试代码实现的功能是减少图像种颜色的数量，将256×256×256转换成26×26×26从而提高程序运行速度。实现该功能需要用到访问图像像素的函数和计时的函数。效果图：测试代码： 一、main函数：1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;time.h&gt;#include &lt;string&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;using namespace std;using namespace cv;void colorReduce(Mat&amp; inputImage,Mat&amp; outputImage,int div);int main()&#123; Mat srcImage = imread(\"1.jpg\"); imshow(\"srcImage\",srcImage); Mat dstImage; dstImage.create(srcImage.rows,srcImage.cols,srcImage.type()); double time0 = static_cast&lt;double&gt;(getTickCount()); colorReduce(srcImage,dstImage,32); time0 = ((double)getTickCount() - time0) / getTickFrequency(); cout &lt;&lt; \"Time: \" &lt;&lt; time0 &lt;&lt; \"s\" &lt;&lt; endl; imshow(\"dstImage\",dstImage); waitKey(0);&#125; 1.计时函数getTickCount()函数返回CPU自某个事件以来走过的时钟周期数getTickFrequency()函数返回CPU一秒钟走过的时钟周期数两者组合如下：123double time0 = static_cast&lt;double&gt;(getTickCount());time0 = ((double)getTickCount() - time0) / getTickFrequency();cout &lt;&lt; \"Time: \" &lt;&lt; time0 &lt;&lt; \"s\" &lt;&lt; endl;即可实现对colorReduce()函数的计时。 2.static_cast函数强制类型转换，即在程序员知情的情况下进行转换，系统不会报错。 二、实现colorReduce()函数的三种方法1.指针访问函数代码：1234567891011121314void colorReduce(Mat&amp; inputImage,Mat&amp; outputImage,int div)&#123; outputImage = inputImage.clone(); int rowNumber = outputImage.rows; int colNumber = outputImage.cols * outputImage.channels(); for(int i = 0; i &lt; rowNumber; i++) &#123; uchar* data = outputImage.ptr&lt;uchar&gt;(i); for(int j = 0; j &lt; colNumber; j++) &#123; data[j] = data[j] / div * div + div / 2; &#125; &#125;&#125;Mat类中的ptr函数可以返回第i行的首地址，如：1uchar* data = outputImage.ptr&lt;uchar&gt;(i); 2.迭代器iterator函数代码：123456789101112void colorReduce(Mat&amp; inputImage,Mat&amp; outputImage,int div)&#123; outputImage = inputImage.clone(); Mat_&lt;Vec3b&gt;::iterator it = outputImage.begin&lt;Vec3b&gt;(); Mat_&lt;Vec3b&gt;::iterator itend = outputImage.end&lt;Vec3b&gt;(); for(;it != itend; ++it) &#123; (*it)[0] = (*it)[0] / div * div + div / 2; (*it)[1] = (*it)[1] / div * div + div / 2; (*it)[2] = (*it)[2] / div * div + div / 2; &#125;&#125;STL 迭代器嘻嘻嘻…自己找 3.动态地址计算函数代码：123456789101112131415void colorReduce(Mat&amp; inputImage,Mat&amp; outputImage,int div)&#123; outputImage = inputImage.clone(); int rowNumber = outputImage.rows; int colNumber = outputImage.cols; for(int i = 0; i &lt; rowNumber; i++) &#123; for(int j = 0; j &lt; colNumber; j++) &#123; outputImage.at&lt;Vec3b&gt;(i,j)[0] = outputImage.at&lt;Vec3b&gt;(i,j)[0] / div * div + div / 2; outputImage.at&lt;Vec3b&gt;(i,j)[1] = outputImage.at&lt;Vec3b&gt;(i,j)[1] / div * div + div / 2; outputImage.at&lt;Vec3b&gt;(i,j)[2] = outputImage.at&lt;Vec3b&gt;(i,j)[2] / div * div + div / 2; &#125; &#125;&#125;Mat类中的at函数可以读取和修改图像矩阵中对应坐标的元素，但是必须在编译时知道图像的数据类型，at函数本身不会进行任何数据类型的转换，因此需要确保我们指定的数据类型要和图像矩阵中的数据类型相同。一般形式：1image.at&lt;Vec3b&gt;(i,j)[channel] = value;在本程序给出的图像是三通道的，因此是Vec3b，表示三个八位数的向量。","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"简单图形绘制","slug":"OpenCV-Learning-Day-8","date":"2019-03-18T11:37:25.000Z","updated":"2019-03-26T02:50:30.462Z","comments":true,"path":"2019/03/18/OpenCV-Learning-Day-8/","link":"","permalink":"http://yoursite.com/2019/03/18/OpenCV-Learning-Day-8/","excerpt":"前言：看毛星云大大的教程的测试代码就把我看晕了……所以没有前言。","text":"前言：看毛星云大大的教程的测试代码就把我看晕了……所以没有前言。 测试代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119#include &lt;iostream&gt;#include &lt;time.h&gt;#include &lt;string&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;using namespace std;using namespace cv;#define WINDOW_WIDTH 600#define WINDOW_NAME1 \"Picture1\"#define WINDOW_NAME2 \"Picture2\"void DrawEllipse(Mat img, double angle);void DrawFilledCircle(Mat img,Point center);void DrawLine(Mat img,Point start,Point end);void DrawPolygon(Mat img);int main()&#123; Mat atomImage = Mat::zeros(WINDOW_WIDTH,WINDOW_WIDTH,CV_8UC3); Mat rookImage = Mat::zeros(WINDOW_WIDTH,WINDOW_WIDTH,CV_8UC3); DrawEllipse(atomImage,90); DrawEllipse(atomImage,0); DrawEllipse(atomImage,45); DrawEllipse(atomImage,-45); DrawFilledCircle(atomImage,Point(WINDOW_WIDTH/2,WINDOW_WIDTH/2)); DrawPolygon(rookImage); rectangle(rookImage, Point(0,7*WINDOW_WIDTH/8), Point(WINDOW_WIDTH,WINDOW_WIDTH), Scalar(0,255,255), -1, 8); 9) DrawLine(rookImage,Point(0,15*WINDOW_WIDTH/16),Point(WINDOW_WIDTH,15*WINDOW_WIDTH/16)); DrawLine(rookImage,Point(WINDOW_WIDTH/4,7*WINDOW_WIDTH/8),Point(WINDOW_WIDTH/4,WINDOW_WIDTH)); DrawLine(rookImage,Point(WINDOW_WIDTH/2,7*WINDOW_WIDTH/8),Point(WINDOW_WIDTH/2,WINDOW_WIDTH)); DrawLine(rookImage,Point(3*WINDOW_WIDTH/4,7*WINDOW_WIDTH/8),Point(3*WINDOW_WIDTH/4,WINDOW_WIDTH)); imshow(WINDOW_NAME1,atomImage); moveWindow(WINDOW_NAME1,0,200); imshow(WINDOW_NAME2,rookImage); moveWindow(WINDOW_NAME2,WINDOW_WIDTH,200); waitKey(0); return(0);&#125;void DrawEllipse(Mat img, double angle)&#123; int thickness = 2; int linetype = 8; ellipse(img, Point(WINDOW_WIDTH/2,WINDOW_WIDTH/2), Size(WINDOW_WIDTH/4,WINDOW_WIDTH/16), angle, 0, 360, Scalar(255,129,0), thickness, linetype);&#125;void DrawFilledCircle(Mat img,Point center)&#123; int thickness = -1; int linetype = 8; circle(img, center, WINDOW_WIDTH/32, Scalar(0,0,255), thickness, linetype);&#125;void DrawPolygon(Mat img)&#123; int linetype = 8; Point rookPoints[1][20]; rookPoints[0][0] = Point(WINDOW_WIDTH/4,7*WINDOW_WIDTH/8); rookPoints[0][1] = Point(3*WINDOW_WIDTH/4,7*WINDOW_WIDTH/8); rookPoints[0][2] = Point(3*WINDOW_WIDTH/4,13*WINDOW_WIDTH/16); rookPoints[0][3] = Point(11*WINDOW_WIDTH/16,13*WINDOW_WIDTH/16); rookPoints[0][4] = Point(19*WINDOW_WIDTH/32,3*WINDOW_WIDTH/8); rookPoints[0][5] = Point(3*WINDOW_WIDTH/4,3*WINDOW_WIDTH/8); rookPoints[0][6] = Point(3*WINDOW_WIDTH/4,WINDOW_WIDTH/8); rookPoints[0][7] = Point(26*WINDOW_WIDTH/40,WINDOW_WIDTH/8); rookPoints[0][8] = Point(26*WINDOW_WIDTH/40,WINDOW_WIDTH/4); rookPoints[0][9] = Point(22*WINDOW_WIDTH/40,WINDOW_WIDTH/4); rookPoints[0][10] = Point(22*WINDOW_WIDTH/40,WINDOW_WIDTH/8); rookPoints[0][11] = Point(18*WINDOW_WIDTH/40,WINDOW_WIDTH/8); rookPoints[0][12] = Point(18*WINDOW_WIDTH/40,WINDOW_WIDTH/4); rookPoints[0][13] = Point(14*WINDOW_WIDTH/40,WINDOW_WIDTH/4); rookPoints[0][14] = Point(14*WINDOW_WIDTH/40,WINDOW_WIDTH/8); rookPoints[0][15] = Point(WINDOW_WIDTH/4,WINDOW_WIDTH/8); rookPoints[0][16] = Point(WINDOW_WIDTH/4,3*WINDOW_WIDTH/8); rookPoints[0][17] = Point(13*WINDOW_WIDTH/32,3*WINDOW_WIDTH/8); rookPoints[0][18] = Point(5*WINDOW_WIDTH/16,13*WINDOW_WIDTH/16); rookPoints[0][19] = Point(WINDOW_WIDTH/4,13*WINDOW_WIDTH/16); const Point* ppt[1] = &#123;rookPoints[0]&#125;; int npt[] = &#123;20&#125;; fillPoly(img, ppt, npt, 1, Scalar(255,255,255), linetype);&#125;void DrawLine(Mat img,Point start,Point end)&#123; int thinkness = 2; int linetype = 8; line(img, start, end, Scalar(0,0,0), thinkness, linetype);&#125;效果图： 一、void DrawEllipse(Mat img, double angle)该函数调用了OpenCV中的ellipse函数用以绘制椭圆。函数原型：1234567891011121314151617181920void ellipse( Mat&amp; img, Point center, Size axes, double angle, double startAngle, double endAngle, const Scalar&amp; color, int thickness=1, int lineType=8, int shift=0)void ellipse( Mat&amp; img, const RotatedRect&amp; box, const Scalar&amp; color, int thickness=1, int lineType=8) 二、void DrawFilledCircle(Mat img,Point center)该函数调用circle函数用以绘制圆形。函数原型：123456789void circle( InputOutputArray img, Point center, int radius, const Scalar &amp;color, int thickness = 1, int lineType = 8, int shift = 0)在测试程序中，由于线粗设置为-1，因此圆形是实心的。 三、void DrawPolygon(Mat img)该函数调用了fillPoly函数用以绘制自定义的多边形。函数原型：12345678910void fillPoly( InputOutputArray img, const Point **pts, const int *npts, int ncontours, const Scalar &amp;color, int lineType = 8, int shift = 0, Point offset = Point())在测试程序中，该函数的多边形的顶点集为ppt，需绘制的多边形顶点数目为npt，绘制图形数量为1。 四、void DrawLine(Mat img,Point start,Point end)函数原型：123456789void line( InputOutputArray img, Point pt1, Point pt2, const Scalar &amp;color, int thickness = 1, int lineType = 8, int shift = 0)无甚可讲。","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"鼠标操作初级","slug":"OpenCV-Learning-Day-7","date":"2019-03-17T00:37:57.000Z","updated":"2019-03-26T02:49:26.945Z","comments":true,"path":"2019/03/17/OpenCV-Learning-Day-7/","link":"","permalink":"http://yoursite.com/2019/03/17/OpenCV-Learning-Day-7/","excerpt":"前言：因为今天天气不错，所以没有前言。","text":"前言：因为今天天气不错，所以没有前言。 测试代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;string&gt;using namespace cv;using namespace std;#define WINDOW_NAME \"SetMouseCallback Sample\"void on_MouseHandle(int event,int x,int y,int flags,void* param);void DrawRectangle(Mat&amp; img,Rect box);void ShowHelpText();Rect g_rectangle;bool g_bDrawingBox = false;RNG g_rng(12345);int main(int argc,char** argv)&#123; g_rectangle = Rect(-1,-1,0,0); Mat srcImage(600,800,CV_8UC3),tempImage; srcImage.copyTo(tempImage); srcImage = Scalar::all(0); namedWindow(WINDOW_NAME); setMouseCallback(WINDOW_NAME,on_MouseHandle,(void*)&amp;srcImage); while(1)&#123; srcImage.copyTo(tempImage); if(g_bDrawingBox) DrawRectangle(tempImage, g_rectangle); imshow(WINDOW_NAME,tempImage); if(waitKey(10) == 27) break; &#125; return 0;&#125;void on_MouseHandle(int event,int x,int y,int flags,void* param)&#123; Mat&amp; image = *(Mat*) param; switch (event) &#123; //鼠标移动消息 case EVENT_MOUSEMOVE: &#123; if (g_bDrawingBox) &#123; g_rectangle.width = x - g_rectangle.x; g_rectangle.height = y - g_rectangle.y; &#125; &#125; break; //左键按下消息 case EVENT_LBUTTONDOWN: &#123; g_bDrawingBox = true; g_rectangle = Rect(x,y,0,0); &#125; break; //左键抬起消息 case EVENT_LBUTTONUP: &#123; g_bDrawingBox = false; //对宽和高小于0的处理 if (g_rectangle.width &lt; 0) &#123; g_rectangle.x += g_rectangle.width; g_rectangle.width *= -1; &#125; DrawRectangle(image,g_rectangle); &#125; break; &#125;&#125;void DrawRectangle(Mat&amp; img,Rect box)&#123; rectangle(img,box.tl(),box.br(),Scalar(g_rng.uniform(0,255),g_rng.uniform(0,255),g_rng.uniform(0,255)));&#125;效果图：setMouseCallback()函数函数原型：12345void setMouseCallback( const String &amp;winname, MouseCallback onMouse, void *userdata = (void *)0)第一个参数为窗口名称第二个参数为MouseCallback类型的onMouse，窗口里每次鼠标操作的发生都会调用这个函数，这个函数的原型：1234567void on_MouseHandle( int event, int x, int y, int flags, void *param)event是许多EVENT_变量，这个在测试程序中有所体现；x和y是在图像坐标系（？）的坐标值，flags是EVENT_FLAG的组合，param是用户定义的传递到setMouseCallback()函数调用的参数。第三个参数是用户定义的传递到回调函数的参数，有默认值0 一、Scalar()函数：函数定义：1234typedef struct Scalar&#123; double val[4];&#125;Scalar;由函数定义可知Scalar()可以存储4个double类型的值，分别对应4通道（需要注意的是，在OpenCV中，前三个颜色通道分别是BGR而不是常识中的RGB，第四个通道则是透明度Alpha值），在使用Scalar()函数的过程中，具体需要使用几个值需要看Mat类型图像的type，比如常见的CV_8UC3类型，C就代表通道（channel），看到C3就知道这个图像有三个通道，因此应该写三个值，每个值分别赋值给对应通道内的所有矩阵元素，如果出现参数比通道数少的情况，那么未赋值的通道内所有矩阵元素全部为0。另科普Mat类型的type参数：1.bit_depth：比特数，代表8bite,16bites,32bites,64bites例如创建一个存储灰度图片的Mat对象,这个图像的大小为宽100,高100,那么,现在这张灰度图片中有10000个像素点，它每一个像素点在内存空间所占的空间大小是8bite,8位，所以它对应的就是CV_82.S|U|FS代表signed int有符号整形U代表unsigned int无符号整形F代表float单精度浮点型3.C（channel）代表一张图片的通道数灰度图片grayImg是单通道图像RGB彩色图像是3通道图像带Alph通道的RGB图像是4通道图像 二、Rect()函数函数定义：1234567typedef struct Rect &#123; int x; /* 方形的左上角的x-坐标 */ int y; /* 方形的左上角的y-坐标*/ int width; /* 宽 */ int height; /* 高 */ &#125;函数用法：123456789101112131415161718192021222324252627282930313233343536373839//如果创建一个Rect对象rect(100, 50, 50, 100)，那么rect会有以下几个功能： rect.area(); //返回rect的面积 5000 rect.size(); //返回rect的尺寸 [50 × 100] rect.tl(); //返回rect的左上顶点的坐标 [100, 50] rect.br(); //返回rect的右下顶点的坐标 [150, 150] rect.width(); //返回rect的宽度 50 rect.height(); //返回rect的高度 100 rect.contains(Point(x, y)); //返回布尔变量，判断rect是否包含Point(x, y)点 //还可以求两个矩形的交集和并集 rect = rect1 &amp; rect2; rect = rect1 | rect2; //还可以对矩形进行平移和缩放 rect = rect + Point(-100, 100); //平移，也就是左上顶点的x坐标-100，y坐标+100 rect = rect + Size(-100, 100); //缩放，左上顶点不变，宽度-100，高度+100 //还可以对矩形进行对比，返回布尔变量 rect1 == rect2; rect1 != rect2; //判断rect1是否在rect2里面bool isInside(Rect rect1, Rect rect2) &#123; return (rect1 == (rect1&amp;rect2)); &#125; //矩形中心点Point getCenterPoint(Rect rect) &#123; Point cpt; cpt.x = rect.x + cvRound(rect.width/2.0); cpt.y = rect.y + cvRound(rect.height/2.0); return cpt; &#125; //围绕矩形中心缩放 Rect rectCenterScale(Rect rect, Size size) &#123; rect = rect + size; Point pt; pt.x = cvRound(size.width/2.0); pt.y = cvRound(size.height/2.0); return (rect-pt); &#125; Rect()函数用法摘自：【OpenCV】cv::Rect矩形类用法blog.csdn.net/qq_30214939/article/details/65648273 三、Rectangle()函数函数原型：123456789void rectangle( InputOutputArray img, Point pt1, Point pt2, const Scalar&amp; color, int thickness = 1, int lineType = LINE_8, int shift = 0)第一个参数是要处理的图片第二和第三个参数分别是矩形的左上角和右下角的坐标第四个参数是矩形的颜色第五个参数是线的粗细第六个参数是线形 四、RNG随机数类型RNG可以产生3种随机数：RNG(int seed)使用种子seed产生一个64位随机整数，默认-1（计算机的伪随机数是由随机种子根据一定的计算方法计算出来的数值，所以只要计算方法一定，随机种子一定，那么产生的随机数就是固定的）RNG::uniform()产生一个均匀分布的随机数（RNG::uniform(a, b )返回一个[a,b)范围的均匀分布的随机数，a,b的数据类型要一致，而且必须是int、float、double中的一种，默认是int）RNG::gaussian( )产生一个高斯分布的随机数（返回一个均值为0，标准差为σ的随机数。如果要产生均值为λ，标准差为σ的随机数，可以λ+ RNG::gaussian( σ)） 五、Mat&amp; image = (Mat) param;的解释param是用户定义的传递到setMouseCallback()函数调用的参数,在本行代码中先将param强制转换为Mat类型指针，然后取param的值赋值给左边作为Mat类型引用的image变量。","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"滑动条创建和使用","slug":"OpenCV-Learning-Day-6","date":"2019-03-16T07:12:39.000Z","updated":"2019-03-26T02:37:08.597Z","comments":true,"path":"2019/03/16/OpenCV-Learning-Day-6/","link":"","permalink":"http://yoursite.com/2019/03/16/OpenCV-Learning-Day-6/","excerpt":"前言没有前言。","text":"前言没有前言。 测试代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;string&gt;using namespace cv;using namespace std;const int g_nMaxAlphaValue = 100; //Alpha值最大值int g_nAlphaValueSlider;//滑动条对应变量double g_dAlphaValue;double g_dBetaValue;Mat g_srcImage1;Mat g_srcImage2;Mat g_dstImage;void on_Trackbar(int, void*)&#123; //Alpha和Beta值的比例 g_dAlphaValue = (double) g_nAlphaValueSlider / g_nMaxAlphaValue; g_dBetaValue = (1.0 - g_dAlphaValue); //根据Alpha和Beta线性混合 addWeighted(g_srcImage1,g_dAlphaValue,g_srcImage2,g_dBetaValue,0,g_dstImage); imshow(\"Trackbar Sample\",g_dstImage);&#125;int main(int argc,char** argv)&#123; //图像尺寸必须相同！！！ g_srcImage1 = imread(\"Paint1.jpg\"); g_srcImage2 = imread(\"Paint2.jpg\"); if(!g_srcImage1.data) &#123; printf(\"Reading image 1 failed\\n\"); return -1; &#125; if(!g_srcImage2.data) &#123; printf(\"Reading image 2 failed\\n\"); return -1; &#125; g_nAlphaValueSlider = 70; namedWindow(\"Trackbar Sample\",1); char TrakbarName[50]; sprintf(TrakbarName,\"Alpha\"); createTrackbar(TrakbarName,\"Trackbar Sample\",&amp;g_nAlphaValueSlider,g_nMaxAlphaValue,on_Trackbar); //运行时初始化界面 on_Trackbar(g_nAlphaValueSlider,0); waitKey(0); return 0;&#125;效果图；Alpha为0时：Alpha为100时： 1.createTrackbar() 函数函数原型：12345678int createTrackbar( const string&amp; trackbarname, const string&amp; winname, int* value, int count, TrackbarCallback onChange=0, void* userdata=0)第一个参数：轨迹条的名字第二个参数：窗口的名字第三个参数：int*类型的指针，指向滑块位置，创建时滑块的位置就是该变量当前的值第四个参数：滑块能达到的最大位置的值第五个参数：TrackbarCallback回调函数，默认为零，滑动条的每一次变化都会调用这个函数，函数原型必须是void XXX(int, void*)，第一个参数是轨迹条的位置，第二个参数是用户传给回调函数的参数，如果第三个参数是全局变量的话，完全可以不用管第六个参数。需要注意的是，读取的图像尺寸必须相同，不然会报错。2.getTrackbarPos()：获取滑动条的位置的值函数原型：1234int getTrackbarPos( const string&amp; trackbarname, const string&amp; winname)","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"图像的简单载入、显示和输出","slug":"OpenCV-Learning-Day-5","date":"2019-03-15T13:27:49.000Z","updated":"2019-03-26T02:37:41.718Z","comments":true,"path":"2019/03/15/OpenCV-Learning-Day-5/","link":"","permalink":"http://yoursite.com/2019/03/15/OpenCV-Learning-Day-5/","excerpt":"前言本章主要介绍图像的简单载入、显示和输出，新内容有namedWindow()函数、图像的ROI（感兴趣区域）以及图像的输出imwrite()函数，顺带科普一下c++文件中常常定义在main函数中的两个形参argc和argv究竟是什么意思～","text":"前言本章主要介绍图像的简单载入、显示和输出，新内容有namedWindow()函数、图像的ROI（感兴趣区域）以及图像的输出imwrite()函数，顺带科普一下c++文件中常常定义在main函数中的两个形参argc和argv究竟是什么意思～ 一、图像的载入、显示和输出测试代码：123456789101112131415161718192021222324252627282930#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;string&gt;using namespace cv;using namespace std;int main()&#123; Mat image = imread(\"Girl.jpg\"); Mat logo = imread(\"logo.jpg\"); namedWindow(\"Girl\"); imshow(\"Girl\",image); namedWindow(\"logo\"); imshow(\"logo\",logo); Mat imageROI; imageROI = image(Rect(1600,2100,logo.cols,logo.rows)); //imageROI = image(Range(2100,2100+logo.rows),Range(1600,1600+logo.cols)); addWeighted(imageROI,0.5,logo,1,0,imageROI); namedWindow(\"Girl+logo\"); imshow(\"Girl+logo\",image); imwrite(\"Output.jpg\",image); waitKey(0); return 0;&#125; 原图： 效果图； 1.为什么会有namedWindow()函数？在简单的图像处理中，我们通常只要读取图像，经过处理后使用imshow()函数输出图像即可，但是在进阶操作中，我们可能会在执行代码生成的窗口上放置滚动条或者按钮，这时候我们就需要在代码执行前就定义这个窗口，这就是namedWindow()函数的作用。函数原型：1234void nameWindow( const string&amp; winname, int flags = WINDOW_AUTOSIZE)其中第二个参数可以设置窗口能否放缩以及是否支持OpenGL。2.ROI（region of interest）感兴趣区域圈定一块图像中需要处理的区域，既节省性能，又便于操作。需要定义一个Mat类型以存放图像的ROI，设置ROI其实就是在原来图片上指定一个区域，而这个区域只是新创建了一个图片文件的头信息而已并没有产生新的图片，文件头里的图片区域的起始位置指向了ROI区域的左上角位置，所以在ROI上做的任何操作都会影响原图片。设置ROI区域有两种方法，测试代码里的注释是另一种，两者效果相同。3.imwrite()函数：输出图像到文件。函数原型：12345bool imwrite( const string&amp; filename, InputArray img, const vector&lt;int&gt;&amp; params=vector&lt;int&gt;())注意：第一个参数文件名要带上后缀 二、argc和argvargc、argv中的arg指的是参数（argument），因此argc的全称为argument counter和argument vector，其中argc为整数，用来统计运行程序时送给main函数的命令行参数的个数；而*argv[]:为字符串数组用来存放指向的字符串参数的指针数组，每一个元素指向一个参数。各成员含义如下：argv[0]指向程序运行的全路径名argv[1]指向在命令行中执行程序名后的第一个字符串argv[2]指向在命令行中执行程序名后的第二个字符串argv[3]指向在命令行中执行程序名后的第三个字符串argv[argv]为NULL","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"基本视频读取和操作","slug":"OpenCV-Learning-Day-4","date":"2019-03-14T08:57:35.000Z","updated":"2019-03-26T02:38:50.375Z","comments":true,"path":"2019/03/14/OpenCV-Learning-Day-4/","link":"","permalink":"http://yoursite.com/2019/03/14/OpenCV-Learning-Day-4/","excerpt":"前言本文主要介绍VideoCapture()函数的使用，包括读取视频和调用摄像头等操作，并结合之前学的一些基本图像处理操作实现视频中物体边缘显示并给出测试代码。对于Mac OS X 10.14无法调用摄像头的问题，文中将给出解决方法。","text":"前言本文主要介绍VideoCapture()函数的使用，包括读取视频和调用摄像头等操作，并结合之前学的一些基本图像处理操作实现视频中物体边缘显示并给出测试代码。对于Mac OS X 10.14无法调用摄像头的问题，文中将给出解决方法。 一、读取视频测试代码：1234567891011121314151617#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;string&gt;using namespace cv;using namespace std;int main()&#123; VideoCapture capture(\"Adventure.mp4\"); //循环显示每一帧 while(1)&#123; Mat frame; capture &gt;&gt; frame; imshow(\"Video\",frame); waitKey(30); &#125; return 0;&#125; 对于声明为VideoCapture类型的参数，只要将其初始化为视频文件的相对路径或者绝对路径，就可以读取视频文件。定义一个Mat类型的变量，通过while循环将视频的每一帧读取到Mat变量中，这样就可以实现图像操作。 二、调用摄像头测试代码：1234567891011121314151617181920212223242526#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/imgproc/imgproc.hpp&gt;#include &lt;string&gt;using namespace cv;using namespace std;int main()&#123; VideoCapture capture(0); //循环显示每一帧 while(1)&#123; Mat srcImage; capture &gt;&gt; srcImage; Mat grayImage, dstImage; Mat grad_x,abs_grad_x,grad_y,abs_grad_y; cvtColor(srcImage,grayImage,COLOR_BGR2GRAY); blur(grayImage,dstImage,Size(3,3)); Sobel(grayImage,grad_x,CV_16S,1,0,3); convertScaleAbs(grad_x,abs_grad_x); Sobel(grayImage,grad_y,CV_16S,0,1,3); convertScaleAbs(grad_y,abs_grad_y); addWeighted(abs_grad_x,0.5,abs_grad_y,0.5,0,dstImage); imshow(\"dstImage\",dstImage); waitKey(30); &#125; return 0;&#125; 对于声明为VideoCapture类型的参数，只要将其初始化为0，就表示调用摄像头。定义一个Mat类型的变量，通过while循环将视频的每一帧读取到Mat变量中，这样就可以实现图像操作。测试代码实现的功能是调用摄像头后通过sobel算子勾勒出物体轮廓。具体sobel函数实现可参考我的上一篇博客：三种基本边缘检测算子www.whoiscaesarbao.com/2019/03/13/OpenCV-Learning-Day-3需要注意的是，Mac OS X 10.14版本存在摄像头无法调用的问题，原因是摄像头权限没给，因此我们要在应用程序文件夹里找到macOS自带的Photo Booth.app，右键选择显示包内容，文件夹里有一个Info.plist文件，默认使用Xcode打开并删去不必要的项，并加入最后一项Privacy - Camera Usage Description 设置为YES，配置后如下图：其中OpenCV是我的项目名，将编辑好的Info.plist文件拷贝到：Xcode为与项目文件夹并列VS Code为与生成的可执行文件并列这样就有权限调用摄像头了。 今天有点水，做数学作业去了～","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"三种基本边缘检测算子","slug":"OpenCV-Learning-Day-3","date":"2019-03-13T11:16:53.000Z","updated":"2019-03-26T02:42:24.640Z","comments":true,"path":"2019/03/13/OpenCV-Learning-Day-3/","link":"","permalink":"http://yoursite.com/2019/03/13/OpenCV-Learning-Day-3/","excerpt":"前言：本片主要介绍三个基本边缘检测的算子（canny算子、sobel算子、laplace算子），关于三个算子的原理和介绍ck2016的简书博客：数字图像 - 边缘检测原理 - Sobel, Laplace, Canny算子www.jianshu.com/p/2334bee37de5 介绍的非常通俗易懂和详细，下面主要放函数原型，测试代码和图片展示～ 原图：","text":"前言：本片主要介绍三个基本边缘检测的算子（canny算子、sobel算子、laplace算子），关于三个算子的原理和介绍ck2016的简书博客：数字图像 - 边缘检测原理 - Sobel, Laplace, Canny算子www.jianshu.com/p/2334bee37de5 介绍的非常通俗易懂和详细，下面主要放函数原型，测试代码和图片展示～ 原图： 一、canny算子：函数原型：123456789101112void cv::Canny ( InputArray image, //输入图像，必须为单通道灰度图 OutputArray edges, //输出图像，为单通道黑白图 double threshold1, double threshold2, //第三个参数和第四个参数表示阈值，这二个阈值中当中的小阈值用来控制边缘连接，大的阈值用来控制强边缘的初始分割，即如果一个像素的梯度大于上限值，则被认为是边缘像素，如果小于下限阈值，则被抛弃。如果该点的梯度在两者之间则当这个点与高于上限值的像素点连接时我们才保留，否则删除。 int apertureSize = 3, //第五个参数表示Sobel 算子大小，默认为3即表示一个3*3的矩阵。Sobel 算子与高斯拉普拉斯算子都是常用的边缘算子 bool L2gradient = false ) 测试代码：1234567891011121314151617181920#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123; Mat srcImage = imread(\"Girl.jpg\"); imshow(\"srcImage\",srcImage); Mat grayImage, dstImage; cvtColor(srcImage,grayImage,COLOR_BGR2GRAY); blur(grayImage,dstImage,Size(3,3)); Canny(dstImage,dstImage,3,9,3); imshow(\"dstImage\",dstImage); waitKey(0);&#125; 效果图： 需要注意的是，canny算子在算出梯度值后会有勾勒边缘的一步：把区域内不是极值的点全部置0，因此效果图中的边缘会变成细线，但同时也会导致一些弱的边缘会被抹去，因此canny算子提供了两个阈值的设置，数值超过大阈值的像素点会被认为是边缘，低于小阈值的像素点被认为不是边缘，数值处于两个阈值之间的，将由周围已经被认为是边缘的像素点开始走格子，可达的是边缘，不可达的被认为不是。阈值的大小比最好为2：1或3：1。 二、sobel算子函数原型：1234567891011void Sobel( InputArray src, //输入图像 OutputArray dst, //输出图像 int ddepth,//目标图像的颜色深度 int dx, //取1表示对x求一阶导数，用来检测竖直边缘 int dy, //取1表示对y求一阶导数，用来检测水平边缘 int ksize=3, //sobel核的大小，必须是奇数，默认为3 double scale=1, double delta=0, int borderType=BORDER_DEFAULT)测试代码：123456789101112131415161718192021222324252627#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123; Mat srcImage = imread(\"Girl.jpg\"); imshow(\"scrImage\",srcImage); Mat grayImage, dstImage; Mat grad_x,abs_grad_x,grad_y,abs_grad_y; //取灰度图和模糊降噪 cvtColor(srcImage,grayImage,COLOR_BGR2GRAY); blur(grayImage,dstImage,Size(3,3)); Sobel(grayImage,grad_x,CV_16S,1,0,3); //sobel算子使用16位有符号的数据类型,防止截断 convertScaleAbs(grad_x,abs_grad_x); //用convertScaleAbs()函数将其转回原来的uint8形式 Sobel(grayImage,grad_y,CV_16S,0,1,3); convertScaleAbs(grad_y,abs_grad_y); addWeighted(abs_grad_x,0.5,abs_grad_y,0.5,0,dstImage); imshow(\"dstImage\",dstImage); waitKey(0);&#125; 效果图： 1.需要注意的是，sobel算子的颜色深度最好使用CV_16S，因为OpenCV文档中对Sobel算子的介绍中有这么一句：“in the case of 8-bit input images it will result in truncated derivatives”。即Sobel函数求完导数后会有负值，还有会大于255的值。而原图像是uint8，即8位无符号数，所以Sobel建立的图像位数不够，会有截断，因此要使用16位有符号的数据类型，即cv2.CV_16S。因此在计算完之后要用convertScaleAbs()函数将其转回原来的uint8形式。2.addWeighted()函数是将两张相同大小，相同类型的图片融合的函数。 函数原型：12345678void cvAddWeighted( const CvArr* src1, //第一个原数组 double alpha,//第一个数组元素权重 const CvArr* src2, //第二个原数值 double beta,//第二个数组元素权重 double gamma, //两个数组作和后添加的数值。不要太大，不然图片一片白。总和等于255以上就是纯白色了 CvArr* dst //输出图像) 三、laplace算子函数原型：123456789void Laplacian( src_gray, //输入图像 dst, //输出图像 ddepth, //因为输入图像一般为CV_8U，为了避免数据溢出，输出图像深度应该设置为CV_16S kernel_size, //核大小，默认为3 scale, delta, BORDER_DEFAULT) 测试代码：123456789101112131415161718192021222324#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123; Mat srcImage = imread(\"Girl.jpg\"); imshow(\"srcImage\",srcImage); Mat grayImage, dstImage; //取灰度图和模糊降噪 cvtColor(srcImage,grayImage,COLOR_BGR2GRAY); blur(grayImage,dstImage,Size(3,3)); Laplacian(grayImage,dstImage,CV_16S,3); convertScaleAbs(dstImage,dstImage); imshow(\"dstImage\",dstImage); waitKey(0);&#125; 效果图： 需要注意的是，由于输入图像是CV_8U格式，但是在使用laplace是为了防止截断需要转换成CV_16S格式，在计算完之后需要convertScaleAbs()函数转换回CV_8U格式，否则是一张灰色图像，别问我怎么知道的。 总结：sobel算子产生的边缘有强弱，抗噪性好。laplace算子对边缘敏感，可能有些是噪声的边缘，也被算进来了。canny算走产生的边缘很细，可能就一个像素那么细，没有强弱之分。 参考资料：【OpenCV入门教程之十二】OpenCV边缘检测：Canny算子,Sobel算子,Laplace算子,Scharr滤波器合辑blog.csdn.net/poem_qianmo/article/details/25560901 数字图像 - 边缘检测原理 - Sobel, Laplace, Canny算子www.jianshu.com/p/2334bee37de5 OpenCV-Python教程（6、Sobel算子）blog.csdn.net/sunny2038/article/details/9170013 Opencv--Sobel算子blog.csdn.net/qq_41248872/article/details/82886228 opencv中addWeighted()函数用法总结（05）blog.csdn.net/fanjiule/article/details/81607873","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"五种基本滤波器","slug":"OpenCV-Learning-Day-2","date":"2019-03-12T13:48:45.000Z","updated":"2019-03-26T02:44:15.456Z","comments":true,"path":"2019/03/12/OpenCV-Learning-Day-2/","link":"","permalink":"http://yoursite.com/2019/03/12/OpenCV-Learning-Day-2/","excerpt":"前言：本片主要介绍五个常见的滤波器（线性滤波、方框滤波、高斯滤波、中值滤波、双边滤波），文章基本是我翻阅博客整理而成的笔记～目前水平太菜了自己写不了基础知识，只能整理大神们的文章了！","text":"前言：本片主要介绍五个常见的滤波器（线性滤波、方框滤波、高斯滤波、中值滤波、双边滤波），文章基本是我翻阅博客整理而成的笔记～目前水平太菜了自己写不了基础知识，只能整理大神们的文章了！ 测试代码：1234567891011121314151617181920212223242526272829#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123; Mat srcImage = imread(\"Bilbo.jpg\"); imshow(\"Input Image\",srcImage); Mat dstImage; blur(srcImage,dstImage,Size(3,3)); imshow(\"blur\",dstImage); boxFilter(srcImage,dstImage,-1,Size(3,3)); imshow(\"boxFilter\",dstImage); GaussianBlur(srcImage,dstImage,Size(3,3),0,0); imshow(\"GaussianBlur\",dstImage); medianBlur(srcImage,dstImage,3); imshow(\"medianBlur\",dstImage); bilateralFilter(srcImage,dstImage,100,0,0); imshow(\"bilateralFilter\",dstImage); waitKey(0);&#125; 效果图： 一、基本滤波器1.线性滤波均值滤波blur：将一个区域内的像素值求和取平均值，然后用这个平均值替换区域中心的像素值。计算速度很快，但是在去躁的同时会模糊很多细节部分，不容易保存细节。 函数原型：1234567void blur( InputArray src, //输入图像 OutputArray dst, //输出图像 Size ksize, //内核大小 Point anchor = Point(-1,-1), //锚点位置，默认为中心点 int borderType = BORDER_DEFAULT //用于推断图像外部像素的某种边界模式，默认值BORDER_DEFAULT) 效果图： 方框滤波boxFilter：算法和均值滤波相似，优缺点也相同，均值滤波算是方框滤波的特殊版本。 效果图： 高斯滤波GaussianBlur：高斯滤波是专门用于消除满足高斯分布(正态分布)的误差而存在的滤波，此时邻域算子是专门的高斯核，图像中的像素与高斯核做卷积，生成的结果加权平均存放到目标像素中，权重按照二维正态分布，对于抑制符合正态分布的噪声非常有效，并可以增强图像值不同比例下的图像效果。 函数原型：123456789void GaussianBlur( InputArray src, OutputArray dst, Size ksize, //表示高斯核函数在Y方向的的标准偏差，若sigmaY为零，就将它设为sigmaX，如果sigmaX和sigmaY都是0，那么就由ksize.width和ksize.height计算出来 double sigmaX, double sigmaY=0, int borderType=BORDER_DEFAULT) 效果图： 2.非线性滤波中值滤波medianBlur：基本思想就是用像素点的领域灰度的中值来代替该像素点的灰度值，该方法在去除脉冲噪声、椒盐噪声的同时又能保留图像的细节（不会出现边缘模糊的情况）。中值滤波跟均值滤波的思想看起来很相似，只是一个取平均值，一个取中位数，但是均值滤波的计算速度是中值滤波的五倍，具体原因可以看总结。 函数原型：12345void medianBlur( InputArray src, OutputArray dst, int ksize //孔径的线性尺寸（aperture linear size），必须为奇数) 效果图： 双边滤波bilateralFilter：双边滤波的最大特点就是做边缘保存，保边去噪。大概的原理是给定一个范围，如果某些区域点与点之间如果数值差距超出范围，那么这个区域就不滤波了，能够很好的保留图像轮廓。函数原型：12345678void bilateralFilter( InputArray src, OutputArray dst, int d, //在过滤过程中每个像素邻域的直径范围 double sigmaColor, //颜色空间过滤器的sigma值 double sigmaSpace, //坐标空间中滤波器的sigma值 int borderType=BORDER_DEFAULT //用于推断图像外部像素的某种边界模式，默认值BORDER_DEFAULT) 注：对sigmaColor、和sigmaSpace两个参数存在比较大的疑惑，因为我不管怎么调后面的参数，效果图好像和原图没有差别…效果图： 3.线性滤波和非线性滤波的区别线性滤波器的原始数据与滤波结果是一种算术运算，即用加减乘除等运算实现，如均值滤波器（模板内像素灰度值的平均值）、高斯滤波器（高斯加权平均值）等。由于线性滤波器是算术运算，有固定的模板，因此滤波器的转移函数是可以确定并且是唯一的（转移函数即模板的傅里叶变换）。 非线性滤波器的原始数据与滤波结果是一种逻辑关系，即用逻辑运算实现，如最大值滤波器、最小值滤波器、中值滤波器等，是通过比较一定邻域内的灰度值大小来实现的，没有固定的模板，因而也就没有特定的转移函数（因为没有模板作傅里叶变换），另外，膨胀和腐蚀也是通过最大值、最小值滤波器实现的。（这就是为什么均值滤波要比中值滤波快五倍的原因：需要通过排序确定中值后才能生成模版） 参考资料：什么是线性滤波、非线性滤波https://www.cnblogs.com/snowxshy/p/3855011.htmlopencv中的各种滤波https://www.jianshu.com/p/8f4024742821OpenCv基本滤波算法小结 blockquotehttps://blog.csdn.net/fzhykx/article/details/79546549opencv中的各种滤波函数https://blog.csdn.net/zoucharming/article/details/70197863OpenCV探索之路（三）：滤波操作https://www.cnblogs.com/skyfsm/p/6873188.html","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"了解卷积：深度学习中的卷积之我见","slug":"Something-Fundamental-about-Convolution","date":"2019-03-11T12:07:09.000Z","updated":"2019-03-11T12:40:04.727Z","comments":true,"path":"2019/03/11/Something-Fundamental-about-Convolution/","link":"","permalink":"http://yoursite.com/2019/03/11/Something-Fundamental-about-Convolution/","excerpt":"一、前言最近在学习OpenCV的过程中接触到了几个常见的算子（canny算子、sobel算子、laplace算子），并对其中的卷积产生了非常大的困惑，此为其一；同时，卷积也可以说是深度学习当中最重要的概念，如CNN神经网络（Conventional Neural Net）更是深度学习中最为常见，也是最为优秀的神经网络之一，此为其二。可以说，卷积是一道不得不迈的门槛，迈过去能办事，迈不过去就只能吹牛了。在翻阅许多博客之后，我发现每个人对卷积的理解都不尽相同，每一篇都能让我有或多或少的收获，但没有一篇能让我完全理解，因此我想站在自己的角度上，稍微谈谈我对卷积以及卷积在深度学习中的使用的一些浅见。","text":"一、前言最近在学习OpenCV的过程中接触到了几个常见的算子（canny算子、sobel算子、laplace算子），并对其中的卷积产生了非常大的困惑，此为其一；同时，卷积也可以说是深度学习当中最重要的概念，如CNN神经网络（Conventional Neural Net）更是深度学习中最为常见，也是最为优秀的神经网络之一，此为其二。可以说，卷积是一道不得不迈的门槛，迈过去能办事，迈不过去就只能吹牛了。在翻阅许多博客之后，我发现每个人对卷积的理解都不尽相同，每一篇都能让我有或多或少的收获，但没有一篇能让我完全理解，因此我想站在自己的角度上，稍微谈谈我对卷积以及卷积在深度学习中的使用的一些浅见。 二、一维卷积及其意义在数学中，卷积地表示是一维的。我们称 (f*g)(n) 为 f,g 的卷积，其连续的定义为：(f∗g)(n)=∫∞−∞f(τ)g(n−τ)dτ其离散的定义为：(f∗g)(n)=∑−∞∞f(τ)g(n−τ) 好家伙，看是看得懂，可卷积出来的结果究竟是个什么东西？它的意义是什么？我看到的最能让我明白的是这两个答案：如何通俗易懂地解释卷积？ - 张俊博的回答 - 知乎https://www.zhihu.com/question/22298352/answer/34267457卷积为什么叫「卷」积？ - 荆哲的回答 - 知乎https://www.zhihu.com/question/54677157/answer/141245297 看完你理解一下就会知道，卷积的一个重要意义就是：一个函数在另一个函数上的加权叠加。在深度学习中，我们把一个函数看作是输入的图像代表的矩阵（Input Image），把另一个图像看作是卷积核（Convolution Kernel），两者卷积，就是输入图像和卷积核的加权叠加，权重越大，卷积值越大，就代表越重要。这是一个陌生的概念，我先按下不提。我之所以会提及一维卷积，是因为一维的卷积更能帮助我们理解卷积的意义：加权叠加。这就是为什么要用卷积的原因所在。 三、人类视觉原理在谈及卷积在深度学习的应用之前，我想先分享一下深度学习神经网络是怎么出现的，这是摘自Alex Cai的博客http://www.cnblogs.com/alexcai/p/5506806.html它更能帮助我们了解神经网络的作用，以及卷积在其中扮演的角色。 深度学习的许多研究成果，离不开对大脑认知原理的研究，尤其是视觉原理的研究。 1981 年的诺贝尔医学奖，颁发给了 David Hubel（出生于加拿大的美国神经生物学家） 和TorstenWiesel，以及 Roger Sperry。前两位的主要贡献，是“发现了视觉系统的信息处理”，可视皮层是分级的。 人类的视觉原理如下：从原始信号摄入开始（瞳孔摄入像素 Pixels），接着做初步处理（大脑皮层某些细胞发现边缘和方向），然后抽象（大脑判定，眼前的物体的形状，是圆形的），然后进一步抽象（大脑进一步判定该物体是只气球）。下面是人脑进行人脸识别的一个示例： 对于不同的物体，人类视觉也是通过这样逐层分级，来进行认知的： 我们可以看到，在最底层特征基本上是类似的，就是各种边缘，越往上，越能提取出此类物体的一些特征（轮子、眼睛、躯干等），到最上层，不同的高级特征最终组合成相应的图像，从而能够让人类准确的区分不同的物体。 那么我们可以很自然的想到：可以不可以模仿人类大脑的这个特点，构造多层的神经网络，较低层的识别初级的图像特征，若干底层特征组成更上一层特征，最终通过多个层级的组合，最终在顶层做出分类呢？答案是肯定的，这也是许多深度学习算法（包括CNN）的灵感来源。 四、深度学习中的卷积由上一节可见，机器学习脱胎于人类视觉原理，而卷积的作用，就是把关键细节抽象化，因为同一类事物总是有各种相同或者相似的细节，记得卷积的作用吗？加权叠加可以提取出相同的、我们所需要的细节并强调它，一层层的提取和强调，就可以生成机器识物的“逻辑”。 在深度学习中，我们所使用的卷积是二维的，因为机器所“看”的图片实质上是一个矩阵，那么相应的，卷积核也是一个矩阵，这个卷积核在 2 维输入数据上“滑动”，对当前输入的部分元素进行矩阵乘法，然后将结果汇为单个输出像素。 这里曾是让我最百思不得其解的地方，可能是智商限制了我的发挥，很长时间有一个问题困扰着我：一维卷积和二维卷积有什么关系？为什么二维卷积会这么计算而不是别的什么方法？其实稍微转换一下角度就很好理解：把输入图像的矩阵和卷积核排成一行而不是将它以二维的形式放置，就会发现它们其实就是f(x)和g(x)以离散的形式所构成的函数！实质上图像正是以这样一种方式，通过训练得出的卷积核，来抽象出图像的特征：强调个性，抑制共性，抽丝剥茧出一套“逻辑”来。 五、后记以上是我在一天的学习后所做的总结，本文没有涉及任何高级的操作，只是我对卷积的一些浅显认识过程。我认为，在深度学习中，打好基础，掌握必要概念非常重要，它会对后面的学习起到意想不到的效果！希望能给予想要学习深度学习的读者一个比较清楚的认识！ 参考链接：如何通俗易懂地解释卷积？ - 张俊博的回答 - 知乎https://www.zhihu.com/question/22298352/answer/34267457卷积为什么叫「卷」积？ - 荆哲的回答 - 知乎https://www.zhihu.com/question/54677157/answer/141245297Alex Cai的博客http://www.cnblogs.com/alexcai/p/5506806.html以及所有我看过的博客们！转载请注明出处","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/categories/Deep-Learning/"}],"tags":[]},{"title":"图像初级操作","slug":"OpenCV-Learning-Day-1","date":"2019-03-10T07:43:23.000Z","updated":"2019-03-26T02:46:13.099Z","comments":true,"path":"2019/03/10/OpenCV-Learning-Day-1/","link":"","permalink":"http://yoursite.com/2019/03/10/OpenCV-Learning-Day-1/","excerpt":"本文内容包括：一、erode 图像腐蚀（dilate 图像膨胀）二、blur 均值滤波三、canny边缘检测 文末提供测试图片","text":"本文内容包括：一、erode 图像腐蚀（dilate 图像膨胀）二、blur 均值滤波三、canny边缘检测 文末提供测试图片 一、erode 图像腐蚀（dilate 图像膨胀）1234567891011121314151617#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123; Mat srcImage = imread(\"Phone.png\"); imshow(\"former\",srcImage); Mat element = getStructuringElement(MORPH_RECT,Size(15,15)); Mat dstImage; erode(srcImage,dstImage,element); imshow(\"later\",dstImage); waitKey(0); return 0;&#125; 1.imread函数只能读取绝对路径，不能读取相对路径，存在疑问。已解决：cmake编译时出现问题，需在CMakeLists.txt中加入一行1aux_source_directory(. DIR_SRCS)对整个文件夹进行扫描即可读取到图片的相对路径。（Xcode肯定没这问题但是我不想用哈哈～谁叫它长得没有VS Code好看） 2.getStructuringElement函数原型：1Mat getStructuringElement(int shape, Size esize, Point anchor = Point(-1, -1));函数的第一个参数表示内核的形状，有三种形状可以选择。矩形：MORPH_RECT;交叉形：MORPH_CORSS;椭圆形：MORPH_ELLIPSE;第二和第三个参数分别是内核的尺寸以及锚点的位置。一般在调用erode以及dilate函数之前，先定义一个Mat类型的变量来获得getStructuringElement函数的返回值。对于锚点的位置，有默认值Point（-1,-1），表示锚点位于中心点。element形状唯一依赖锚点位置，其他情况下，锚点只是影响了形态学运算结果的偏移。 3.erode 图像腐蚀（dilate 图像膨胀）erode 函数原型：12void erode( const Mat&amp; src, Mat&amp; dst, const Mat&amp; element,Point anchor=Point(-1,-1), int iterations=1,int borderType=BORDER_CONSTANT,const Scalar&amp; borderValue=morphologyDefaultBorderValue() );dilate 函数原型：12void dilate( const Mat&amp; src, Mat&amp; dst, const Mat&amp; element,Point anchor=Point(-1,-1), int iterations=1,int borderType=BORDER_CONSTANT,const Scalar&amp; borderValue=morphologyDefaultBorderValue() );参数：src:原图像。dst：目标图像。element:腐蚀操作的内核。 如果不指定，默认为一个简单的 3x3 矩阵。否则，我们就要明确指定它的形状，可以使用函数getStructuringElement().anchor:默认为Point(-1,-1),内核中心点。省略时为默认值。iterations:腐蚀次数。省略时为默认值1。borderType:推断边缘类型，具体参见borderInterpolate函数。默认为BORDER_DEFAULT，省略时为默认值。borderValue:边缘值，具体可参见createMorphoogyFilter函数。可省略。 二、blur 均值滤波1234567891011121314#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123; Mat srcImage = imread(\"Phone.png\"); imshow(\"src\",srcImage); Mat dstImage; blur(srcImage,dstImage,Size(7,7)); imshow(\"dst\",dstImage); waitKey(0);&#125; 均值滤波是一种典型的线性滤波算法，主要是利用像素点邻域的像素值来计算像素点的值。其具体方法是首先给出一个滤波模板kernel，该模板将覆盖像素点周围的其他邻域像素点，去掉像素本身，将其邻域像素点相加然后取平均值即为该像素点的新的像素值，这就是均值滤波的本质。函数原型：1void blur(InputArray src, OutputArray dst, Size ksize, Point anchor=Point(-1,-1), int borderType=BORDER_DEFAULT);参数解释：InputArray src: 输入图像OutputArray dst: 输出图像Size ksize: 滤波模板kernel的尺寸，如Size(3,3)Point anchor=Point(-1, -1): 字面意思是锚点，也就是处理的像素位于kernel的什么位置，默认值为(-1, -1)即位于kernel中心点，如果没有特殊需要则不需要更改int borderType=BORDER_DEFAULT: 用于推断图像外部像素的某种边界模式，有默认值BORDER_DEFAULT 三、canny边缘检测12345678910111213141516171819202122232425262728#include&lt;opencv2/opencv.hpp&gt;#include&lt;opencv2/highgui/highgui.hpp&gt;#include&lt;opencv2/imgproc/imgproc.hpp&gt;#include&lt;string&gt;using namespace cv;using namespace std;int main()&#123; Mat srcImage = imread(\"Phone.png\"); //原图像 imshow(\"src\",srcImage); Mat dstImage,edge,grayImage; //创建与srcImage同大小和同类型的矩阵 dstImage.create(srcImage.size(),srcImage.type()); //转换成灰度图像 cvtColor(srcImage,grayImage,COLOR_BGR2GRAY); //使用滤波函数降噪，这里用的是10*10内核 blur(grayImage,edge,Size(10,10)); //运行canny算子 Canny(edge,edge,3,9,3); //目标图像 imshow(\"dst\",edge); waitKey(0);&#125; 1.cvtColor颜色空间转换函数函数原型：123456void cvtColor( InputArray src, // 输入图像 OutputArray dst, // 输出图像 int code, // 颜色映射码 int dstCn = 0 // 输出的通道数 (0='automatic') )cvtColor()支持多种颜色空间之间的转换，目前常见的颜色空间均支持，并且在转换的过程中能够保证数据的类型不变，即转换后的图像的数据类型和位深与源图像一致。 2.canny算法Canny边缘检测于1986年由JOHN CANNY首次在论文《A Computational Approach to Edge Detection》中提出，就此拉开了Canny边缘检测算法的序幕。Canny边缘检测是从不同视觉对象中提取有用的结构信息并大大减少要处理的数据量的一种技术，目前已广泛应用于各种计算机视觉系统。函数原型：123456789101112void cv::Canny ( InputArray image, //输入图像，必须为单通道灰度图 OutputArray edges, //输出图像，为单通道黑白图 double threshold1, double threshold2, //第三个参数和第四个参数表示阈值，这二个阈值中当中的小阈值用来控制边缘连接，大的阈值用来控制强边缘的初始分割，即如果一个像素的梯度大于上限值，则被认为是边缘像素，如果小于下限阈值，则被抛弃。如果该点的梯度在两者之间则当这个点与高于上限值的像素点连接时我们才保留，否则删除。 int apertureSize = 3, //第五个参数表示Sobel 算子大小，默认为3即表示一个3*3的矩阵。Sobel 算子与高斯拉普拉斯算子都是常用的边缘算子 bool L2gradient = false ) 阈值的大小比最好为2：1或3：1。 测试图像：","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/categories/OpenCV/"}],"tags":[]},{"title":"Mac 使用VS Code 通过cmake 配置 OpenCV和Pytorch C++ API","slug":"Deep-Learning-Starting","date":"2019-03-05T15:16:11.000Z","updated":"2019-03-26T02:47:59.331Z","comments":true,"path":"2019/03/05/Deep-Learning-Starting/","link":"","permalink":"http://yoursite.com/2019/03/05/Deep-Learning-Starting/","excerpt":"前情由于pytorch的1.0正式版发布不久，同时较为稳定的c++的API也是在正式版中提供支持，网上的教程不多，因此可供参考的资料只有官方文档和零零散散的博客。不过由于Mac和Linux本身相差不大，一些Linux的配置教程同样值得参考。以下给出链接：官方文档https://pytorch.org/cppdocs/installing.htmlOldpan的个人博客（特别感谢Oldpan老哥的帖子给我的巨大帮助）：利用Pytorch的C++前端(libtorch)读取预训练权重并进行预测：https://oldpan.me/archives/pytorch-c-libtorch-inferencePytorch源码编译简明指南：https://m.oldpan.me/archives/pytorch-build-simple-instruction","text":"前情由于pytorch的1.0正式版发布不久，同时较为稳定的c++的API也是在正式版中提供支持，网上的教程不多，因此可供参考的资料只有官方文档和零零散散的博客。不过由于Mac和Linux本身相差不大，一些Linux的配置教程同样值得参考。以下给出链接：官方文档https://pytorch.org/cppdocs/installing.htmlOldpan的个人博客（特别感谢Oldpan老哥的帖子给我的巨大帮助）：利用Pytorch的C++前端(libtorch)读取预训练权重并进行预测：https://oldpan.me/archives/pytorch-c-libtorch-inferencePytorch源码编译简明指南：https://m.oldpan.me/archives/pytorch-build-simple-instruction 开始所需安装的工具有：1.VS Code：这个官网下载即可2.OpenCV 4.0.1:终端输入1brew install opencv即可安装3.Pytorch1.0:可参考上面给出的Pytorch源码编译简明指南，首先在终端输入1git clone --recursive https://github.com/pytorch/pytorch获取最新源码，然后通过编译得到Mac可以读取的.dylib文件（注意：在官方文档中下载的libtorch-shared-with-deps-latest.zip文件解压后所得到的文件夹里的动态库文件是以.so结尾，是Linux下的动态库文件，Mac识别不了）编译时应该先进入到刚刚下载好的Pytorch文件夹（默认的路径应该是/Users/用户名/pytorch）下，然后终端执行123mkdir buildcd buildpython ../tools/build_libtorch.py进行libtorch（即c++ API）的编译，时间较长。4.编译好之后打开VS Code新建一个工程，在这里我引用Oldpan老哥的例子 工程名叫simnet，然后在simnet文件夹下新建一个CMakeLists.txt和一个test.cpp（build先不建），CMakeLists.txt中的代码为：123456789101112131415161718192021cmake_minimum_required(VERSION 3.12 FATAL_ERROR)project(simnet)find_package(Torch REQUIRED) # 查找libtorchfind_package(OpenCV REQUIRED) # 查找OpenCVif(NOT Torch_FOUND)message(FATAL_ERROR \"Pytorch Not Found!\")endif(NOT Torch_FOUND)message(STATUS \"Pytorch status:\")message(STATUS \" libraries: $&#123;TORCH_LIBRARIES&#125;\")message(STATUS \"OpenCV library status:\")message(STATUS \" version: $&#123;OpenCV_VERSION&#125;\")message(STATUS \" libraries: $&#123;OpenCV_LIBS&#125;\")message(STATUS \" include path: $&#123;OpenCV_INCLUDE_DIRS&#125;\")add_executable(simnet test.cpp)target_link_libraries(simnet $&#123;TORCH_LIBRARIES&#125; $&#123;OpenCV_LIBS&#125;) set_property(TARGET simnet PROPERTY CXX_STANDARD 11) test.cpp中的代码为：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include &lt;opencv2/opencv.hpp&gt;#include \"torch/script.h\"#include \"torch/torch.h\"#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std;// resize并保持图像比例不变cv::Mat resize_with_ratio(cv::Mat&amp; img) &#123; cv::Mat temImage; int w = img.cols; int h = img.rows; float t = 1.; float len = t * std::max(w, h); int dst_w = 224, dst_h = 224; cv::Mat image = cv::Mat(cv::Size(dst_w, dst_h), CV_8UC3, cv::Scalar(128,128,128)); cv::Mat imageROI; if(len==w) &#123; float ratio = (float)h/(float)w; cv::resize(img,temImage,cv::Size(224,224*ratio),0,0,cv::INTER_LINEAR); imageROI = image(cv::Rect(0, ((dst_h-224*ratio)/2), temImage.cols, temImage.rows)); temImage.copyTo(imageROI); &#125; else &#123; float ratio = (float)w/(float)h; cv::resize(img,temImage,cv::Size(224*ratio,224),0,0,cv::INTER_LINEAR); imageROI = image(cv::Rect(((dst_w-224*ratio)/2), 0, temImage.cols, temImage.rows)); temImage.copyTo(imageROI); &#125; return image;&#125;int main(int argc, const char* argv[])&#123; if (argc != 2) &#123; std::cerr &lt;&lt; \"usage: example-app &lt;path-to-exported-script-module&gt;\\n\"; return -1; &#125; cv::VideoCapture stream(0); cv::namedWindow(\"Gesture Detect\", cv::WINDOW_AUTOSIZE); std::shared_ptr&lt;torch::jit::script::Module&gt; module = torch::jit::load(argv[1]); module-&gt;to(at::kCUDA); cv::Mat frame; cv::Mat image; cv::Mat input; while(1) &#123; stream&gt;&gt;frame; image = resize_with_ratio(frame); imshow(\"resized image\",image); //显示摄像头的数据 cv::cvtColor(image, input, cv::COLOR_BGR2RGB); // 下方的代码即将图像转化为Tensor，随后导入模型进行预测 torch::Tensor tensor_image = torch::from_blob(input.data, &#123;1,input.rows, input.cols,3&#125;, torch::kByte); tensor_image = tensor_image.permute(&#123;0,3,1,2&#125;); tensor_image = tensor_image.toType(torch::kFloat); tensor_image = tensor_image.div(255); tensor_image = tensor_image.to(torch::kCUDA); torch::Tensor result = module-&gt;forward(&#123;tensor_image&#125;).toTensor(); auto max_result = result.max(1, true); auto max_index = std::get&lt;1&gt;(max_result).item&lt;float&gt;(); if(max_index == 0) cv::putText(frame, \"paper\", &#123;40, 50&#125;, cv::FONT_HERSHEY_PLAIN, 2.0, cv::Scalar(0, 255, 0), 2); else if(max_index == 1) cv::putText(frame, \"scissors\", &#123;40, 50&#125;, cv::FONT_HERSHEY_PLAIN, 2.0, cv::Scalar(0, 255, 0), 2); else cv::putText(frame, \"stone\", &#123;40, 50&#125;, cv::FONT_HERSHEY_PLAIN, 2.0, cv::Scalar(0, 255, 0), 2); imshow(\"Gesture Detect\",frame); //显示摄像头的数据 cv::waitKey(30);&#125; 保存。 5.终端cd进入simnet工程文件夹，然后执行1234mkdir buildcd buildcmake -DCMAKE_PREFIX_PATH=/absolute/path/to/pytorch ..make其中/absolute/path/to/pytorch是pytorch文件夹的绝对路径，一般是/Users/用户名/pytorch这样就编译完成了可以执行1./simnet来运行你的工程了！ 后记由于这是我第一次写教程，很多地方可能有所疏漏，并且配置的过程中踩了无数的坑，可能很多地方起了效果但是我根本没有注意到，还有前期的一些准备工作我也没有提及（比如说anaconda的安装，pip、conda、brew的安装和更新），这些网上有很多大佬写的非常详尽的教程，大家可以多多参考，我这里只是提供了一个自己的思路，如果没有安装成功还望见谅！","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/categories/Deep-Learning/"}],"tags":[]},{"title":"《La La Land》：有关闪耀而易碎的、遗憾而完美的那些事","slug":"Land","date":"2019-01-21T10:41:25.000Z","updated":"2019-01-21T15:11:33.956Z","comments":true,"path":"2019/01/21/Land/","link":"","permalink":"http://yoursite.com/2019/01/21/Land/","excerpt":"City of stars, are you shining for me?","text":"City of stars, are you shining for me? LA，los angeles，city of stars，确实太过闪耀，有太多人，哪怕从未踏上洛杉矶的土地，也对那里根种了太多美好的幻想。我想起几年前我拿着我新买的PS4，打开《GTA V》的时候，我的天！主角Michael的家外边就是粼粼的海面和充满“热情”的沙滩，无云而湛蓝的天际延伸至远处渐渐变淡，与海面交融直至分不清楚。坐上红色跑车，手搭在车窗上，沿着海岸线一路向北，深红色的岩石蒸腾着热气，视线延伸向上看见绿色————是棕榈树————阳光刺眼，模模糊糊，看不真切；渐入钢铁丛林，阳光也是热辣的吓人，大片大片的反光，大片大片的明媚，西装革履的男人，潮流青年，穿休闲服遛狗的人，酒鬼，或昂首挺胸，或散散漫漫，或失魂落魄，穿梭在层层叠叠的阴影和光斑之间，完美融进这这城市里，一如他们迥然的处境和各不相同的命运。也许是Rockstar太过顶级的美工，又有可能是他们早年的作品圣安第列斯已经满足了我的杀戮欲望，现在我规规矩矩地在马路上开着我的车，老老实实的等着红灯熄灭，绿灯闪烁，循规蹈矩的和其他市民一般驾驶。再往上开，房子渐渐的又变矮了，地势升高，一块巨大的标牌从山顶慢慢向我挪来。我慢慢驶近，在不经意间，它突然变得明亮起来。 啊，HOLLY WOOD。 闪亮的灯牌提醒我天色已晚。我下了车，站在富人区的山顶上，眺望着整个圣洛都。细小闪耀的灯光如同沙粒，连着川流不息的车流，成了江成了河，向我诉说这座钢之巨人自他从这片泥土地里诞生起便永不入睡。是啊，它是如此勤奋地活着，连同它身体里的人们，仿佛都是永不入睡的，为了梦想，为了家庭，为了生活，抑或是吸了毒嗨了药，who cares？圣洛都的天空，是我见过的最美的天空————渐变色的，难以形容————或者可以想象一下，你现在正在一个晚宴上，和你心仪的人交谈，总有那么一两个时候你会觉得羞涩，心里有头小鹿撞来撞去，眼神不知道该往哪里看；于是你只好低头盯着你手里拿着的酒杯，因为这样显得你优雅而有礼貌，你开始端详葡萄酒的颜色：深红的葡萄酒被晚宴上昏暗的光线一打，自底向上由浅入深，不断的变换着色彩，可能是浅粉色，可能是淡蓝色，可能是深紫色；你挪动酒杯，颜色也跟着变化————是了，这就是LA的夜空，不仅仅是渐变的，柔和的，绚丽的，同时，它也是暧昧的，易碎的，不可告人的。 后来我打通了游戏，我最后一次看着Michael，Franklin，Trevor站在一起，看着车子渐渐沉进海底，三个人各自说着像总结一样的话，仿佛是隔着屏幕告诉我们他们的故事到这里就结束了，从今往后他们三个再在哪里相见，以什么样的方式相见，都不再关我的事，自北扬克顿拉开帷幕的故事到这里收场，生活还要继续；后来，因为学习，我（被强迫）收起了我的PS4，到那个时候我已经能轻车熟路的开遍圣洛都的大街小巷，我已然成为了一个老圣洛都人；可是那一晚，我打开我新买的PS4，打开我新买的《GTA V》，逛了逛海滩，坐上我的红色跑车，一路向北……那一幕幕带给我的震撼，我将永远不会忘记。因为是从那个时候起，我真正地将游戏打心底里视为一种艺术，而不是什么害人的消遣，到后来，我从网上知道原来GTA系列是描述美国梦的，我总是不由自主地和那个夜晚联系在一起——繁华的，易碎的，暧昧的，不可告人的……大概就是这样的吧。 我写了这么长的铺垫，其实是想告诉你，为什么我会对这部电影感触如此之深：不仅仅是因为我再次看到了那些似曾相识的场景，美丽的难以忘怀；而且我还看到了另一个故事，有关美国梦的故事，美好的令人心碎。一如这部电影的画面，我明知现实生活中不可能发生这样的故事，却根本不愿意去质疑。就让我带着迷蒙的的眼神，盯着那只葡萄酒杯；就让我微醺的脸色，更浓一分吧。 就当我做了一个梦，而我选择再不复醒。 还没写完先放放。","categories":[{"name":"Film Comment","slug":"Film-Comment","permalink":"http://yoursite.com/categories/Film-Comment/"}],"tags":[]}]}